{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4661571d-f694-40f3-aae3-d9f723eb5048",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import tqdm, tqdm.notebook\n",
    "tqdm.tqdm = tqdm.notebook.tqdm  # notebook-friendly progress bars\n",
    "from pathlib import Path\n",
    "from pprint import pformat\n",
    "\n",
    "from hloc import extract_features, match_features, reconstruction, visualization, pairs_from_exhaustive\n",
    "from hloc import reconstruction_belv\n",
    "from hloc.visualization import plot_images, read_image\n",
    "from hloc.utils import viz_3d\n",
    "\n",
    "import h5py\n",
    "import pickle\n",
    "import pycolmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02aae1d6-b13b-466e-9991-240a38f238dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Path('./epoch0')\n",
    "images = Path(dataset / 'images/')\n",
    "# outputs = Path(dataset)\n",
    "# !rm -rf $outputs\n",
    "sfm_pairs = dataset / 'pairs-sfm.txt'\n",
    "loc_pairs = dataset / 'pairs-loc.txt'\n",
    "sfm_dir = dataset\n",
    "features = dataset / 'features.h5'\n",
    "matches = dataset / 'matches.h5'\n",
    "\n",
    "feature_conf = extract_features.confs['superpoint_aachen']\n",
    "matcher_conf = match_features.confs['superglue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f578cbae-fa21-41ee-a2f9-7ee2688f44c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_images = [p.relative_to(images).as_posix() for p in (images).iterdir()]\n",
    "print(len(ref_images), \"images\")\n",
    "# plot_images([read_image(images / r) for r in references[:4]], dpi=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96001241-70e6-4abf-aa01-9f314933b88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract_features.main(feature_conf, images, image_list=references, feature_path=features)\n",
    "# pairs_from_exhaustive.main(sfm_pairs, image_list=references)\n",
    "# match_features.main(matcher_conf, sfm_pairs, features=features, matches=matches);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3fcd55-c261-4903-8e5e-413d76214a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_h5datasets(matches_path, pair):\n",
    "    from hloc.utils.io import (list_h5_names, get_matches, get_keypoints, find_pair) \n",
    "    from hloc.utils.parsers import names_to_pair\n",
    "    import h5py\n",
    "    \n",
    "    # Retrieve matched features with SG and build HDF5 datasets\n",
    "    with open(matches_path, 'rb') as f:\n",
    "        mfeats = pickle.load(f)\n",
    "    # print(mfeats)\n",
    "\n",
    "    # Build hdf5 features datasets\n",
    "    pair = names_to_pair(pair[0], pair[1])\n",
    "    data = {'keypoints': mfeats[0]['mkpts0'],\n",
    "           'descriptors': mfeats[0]['descr0'], \n",
    "           'scores': mfeats[0]['scores0']} \n",
    "    name = pair[0]\n",
    "    with h5py.File(features, 'a') as fd:\n",
    "        if name in fd:\n",
    "            del fd[name]\n",
    "        grp = fd.create_group(name)\n",
    "        for k, v in data.items():\n",
    "            grp.create_dataset(k, data=v)\n",
    "\n",
    "    data = {'keypoints': mfeats[0]['mkpts1'],\n",
    "           'descriptors': mfeats[0]['descr1'], \n",
    "           'scores': mfeats[0]['scores1']} \n",
    "    name = pair[1]\n",
    "    with h5py.File(features, 'a') as fd:\n",
    "        if name in fd:\n",
    "            del fd[name]\n",
    "        grp = fd.create_group(name)\n",
    "        for k, v in data.items():\n",
    "            grp.create_dataset(k, data=v)\n",
    "\n",
    "    # Build hdf5 matching datasets\n",
    "    matchArray = []\n",
    "    matchScores = []\n",
    "    npts = len(mfeats[0]['mkpts1'])\n",
    "    for i in range(0, npts):\n",
    "        matchArray.append(i)\n",
    "        matchScores.append(1)\n",
    "\n",
    "    pair = names_to_pair(pair[0], pair[1])\n",
    "    with h5py.File(dataset / \"matches.h5\",'a') as fd:\n",
    "        if pair in fd:\n",
    "            del fd[pair]\n",
    "        grp = fd.create_group(pair)\n",
    "        grp.create_dataset('matches0', data=matchArray)\n",
    "        grp.create_dataset('matching_scores0', data=matchScores)\n",
    "\n",
    "\n",
    "sgmatches_path = Path(dataset / 'IMG_0520_IMG_2131_features.pickle')\n",
    "build_h5datasets(sgmatches_path, ref_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e84f97-ee5e-421c-830d-874e15ac19d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run reconstruction\n",
    "pycolmap.CameraMode.__members__.keys()\n",
    "pairs_from_exhaustive.main(sfm_pairs, image_list=ref_images)\n",
    "model = reconstruction.main(sfm_dir, images, sfm_pairs, features, matches, image_list=ref_images, verbose = True,  camera_mode=pycolmap.CameraMode.PER_IMAGE)\n",
    "model.write_text(str(sfm_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c36028-04bc-4a90-9a1f-aaa982cce55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = viz_3d.init_figure()\n",
    "viz_3d.plot_reconstruction(fig, model, color='rgba(255,0,0,0.5)', name=\"mapping\")\n",
    "fig.show()\n",
    "visualization.visualize_sfm_2d(model, images, color_by='depth', n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c74ba0-c206-4439-94a8-b24994f9a8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_id, image in model.images.items():\n",
    "    print(image_id, image)\n",
    "# for point3D_id, point3D in reconstructionObj.points3D.items():\n",
    "#     print(point3D_id, point3D)\n",
    "for camera_id, camera in model.cameras.items():\n",
    "    print(camera_id, camera)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff53340-7e8a-4bb0-be46-0c882e08478f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# import os\n",
    "# import argparse\n",
    "\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument(\"--database_path\", default=\"database.db\")\n",
    "# args = parser.parse_args()\n",
    "\n",
    "# if os.path.exists(args.database_path):\n",
    "#     print(\"ERROR: database path already exists -- will not modify it.\")\n",
    "#     return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a170e2b-c28c-4152-b763-ce3553fbf9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run recosnstruction with custom camera\n",
    "pairs_from_exhaustive.main(sfm_pairs, image_list=ref_images)\n",
    "\n",
    "# Define cameras\n",
    "model = \"FULL_OPENCV\"\n",
    "width = 6000\n",
    "height = 4000\n",
    "params1 = np.array((10145.828770984808, 10181.29619861736,  2928.763582703865, 1636.663975450278, -0.04643331697636249, 0.7615948374750167, -0.010397811196689507, -0.002202286738591026, -4.287589186049892, 0., 0., 0.))\n",
    "params2 = np.array((6900.766178626993, 6919.0517432373235, 3055.9219427396583, 1659.8768050681379, -0.07241143420209739, 0.00311945599198001, -0.008597066196675609, 0.002601995972163532, 0.46863386164346776, 0., 0., 0.))\n",
    "camera1_dict = {\n",
    "    'model': model,\n",
    "    'width': width,\n",
    "    'height': height,\n",
    "    'params': params1\n",
    "}\n",
    "camera2_dict = {\n",
    "    'model': model,\n",
    "    'width': width,\n",
    "    'height': height,\n",
    "    'params': params2\n",
    "}\n",
    "\n",
    "# model = reconstruction_belv.main(sfm_dir, images, sfm_pairs, features, matches, image_list=references, verbose = True,  camera_mode=pycolmap.CameraMode.PER_IMAGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fed728-a89d-4a48-8ca6-eff8072df932",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hloc.reconstruction_belv import create_empty_db\n",
    "\n",
    "database_path = sfm_dir / 'database.db'\n",
    "create_empty_db(database_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b0ef30-0f78-4ab5-843e-1fa2f27f0ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# void import_images(const py::object database_path_,\n",
    "#                    const py::object image_path_,\n",
    "#                    const CameraMode camera_mode,\n",
    "#                    const std::string camera_model,\n",
    "#                    const std::vector<std::string> image_list)\n",
    "\n",
    "# cam1 = pycolmap.Camera(\n",
    "#     model= model,\n",
    "#     width= width,\n",
    "#     height= height,\n",
    "#     params= params1,\n",
    "# )\n",
    " \n",
    "from hloc.reconstruction_belv import get_image_ids\n",
    "from hloc.triangulation_belv import (import_features,import_matches)\n",
    "\n",
    "def import_images(image_dir, database_path, camera_mode, camera_model, image_list=None):\n",
    "    logger.info('Importing images into the database...')\n",
    "    images = list(image_dir.iterdir())\n",
    "    if len(images) == 0:\n",
    "        raise IOError(f'No images found in {image_dir}.')\n",
    "    with pycolmap.ostream():\n",
    "        pycolmap.import_images(database_path, image_dir, camera_mode, camera_model,\n",
    "                               image_list=image_list or [])    \n",
    "\n",
    "import_images(sfm_dir, database_path, 'PER_IMAGE', 'FULL_OPENCV', ref_images)\n",
    "image_ids = get_image_ids(database_path)    \n",
    "import_features(image_ids, database_path, features)\n",
    "# import_matches(image_ids, database_path, sfm_pairs, matches)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a8151f-bdb4-4158-84e2-e6ecf107050e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import database\n",
    "from hloc import logger\n",
    "from hloc.utils.database import COLMAPDatabase\n",
    "from hloc.reconstruction_belv import create_empty_db\n",
    "\n",
    "assert features.exists(), features\n",
    "assert sfm_pairs.exists(), sfm_pairs\n",
    "assert matches.exists(), matches\n",
    "\n",
    "database_path = sfm_dir / 'database.db'\n",
    "create_empty_db(database_path)\n",
    "\n",
    "# sfm_dir.mkdir(parents=True, exist_ok=True)\n",
    "# database_path = sfm_dir / 'database.db'\n",
    "# # Open the database (remove previous one, if already exists)\n",
    "# if os.path.exists(database_path):\n",
    "#     os.remove(database_path)\n",
    "    \n",
    "# if database_path.exists():\n",
    "#     logger.warning('The database already exists, deleting it.')\n",
    "#     database_path.unlink()\n",
    "# logger.info('Creating new database...')\n",
    "\n",
    "database = COLMAPDatabase.connect(database_path)\n",
    "database.create_tables()\n",
    "\n",
    "# Create Cameras\n",
    "camera_id1 = database.add_camera(camera1_dict['model'], camera1_dict['width'], \n",
    "                           camera1_dict['height'], camera1_dict['params'])\n",
    "camera_id2 = database.add_camera(camera2_dict['model'], camera2_dict['width'], \n",
    "                           camera2_dict['height'], camera2_dict['params'])\n",
    "\n",
    "# Create images.\n",
    "image_id1 = database.add_image(str(images/ref_images[0]), camera_id1)\n",
    "image_id2 = database.add_image(str(images/ref_images[1]), camera_id2)\n",
    "\n",
    "# Commit the data to the file.\n",
    "database.commit()\n",
    "database.close()\n",
    "\n",
    "from hloc.reconstruction_belv import get_image_ids\n",
    "from hloc.triangulation_belv import (import_features,import_matches)\n",
    "\n",
    "image_ids = get_image_ids(database_path)    \n",
    "import_features(image_ids, database_path, features)\n",
    "import_matches(image_ids, database_path, sfm_pairs, matches)\n",
    "# if not skip_geometric_verification:\n",
    "#     geometric_verification(database, pairs, verbose)\n",
    "\n",
    "\n",
    "# from hloc.utils.io import (get_keypoints, get_matches)\n",
    "# def import_matches(image_ids, database_path, pairs_path, matches_path,\n",
    "#                    min_match_score=None, skip_geometric_verification=False):\n",
    "#     logger.info('Importing matches into the database...')\n",
    "    \n",
    "#     with open(str(pairs_path), 'r') as f:\n",
    "#         pairs = [p.split() for p in f.readlines()]\n",
    "    \n",
    "#     db = COLMAPDatabase.connect(database_path)\n",
    "#     matched = set()\n",
    "    \n",
    "#     for name0, name1 in pairs:\n",
    "#         images_path = [path for path, v in image_ids.items()]\n",
    "#         id0, id1 = image_ids[images_path[0]], image_ids[images_path[1]]\n",
    "#         if len({(id0, id1), (id1, id0)} & matched) > 0:\n",
    "#             continue\n",
    "#         matches, scores = get_matches(matches_path, name0, name1)\n",
    "#         if min_match_score:\n",
    "#             matches = matches[scores > min_match_score]\n",
    "#         db.add_matches(id0, id1, matches)\n",
    "#         matched |= {(id0, id1), (id1, id0)}\n",
    "\n",
    "#         if skip_geometric_verification:\n",
    "#             db.add_two_view_geometry(id0, id1, matches)\n",
    "\n",
    "#     db.commit()\n",
    "#     db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9edab9-99eb-46cd-aec0-c39f9515014e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hloc.reconstruction_belv import run_reconstruction\n",
    "\n",
    "reconstruction = run_reconstruction(sfm_dir, database_path, sfm_pairs, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddc6899-dd27-46b7-902e-9ba00a279b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import database\n",
    "\n",
    "database_path =  str(dataset / \"database.db\")\n",
    "\n",
    "# Open the database (remove previous one, if already exists)\n",
    "if os.path.exists(database_path):\n",
    "    os.remove(database_path)\n",
    "    \n",
    "db = database.COLMAPDatabase.connect(database_path)\n",
    "\n",
    "# Try creating all the tables upfront.\n",
    "db.create_tables()\n",
    "\n",
    "# Create cameras.\n",
    "model = \"FULL_OPENCV\"\n",
    "width = 6000\n",
    "height = 4000\n",
    "params1 = np.array((10145.828770984808, 10181.29619861736,  2928.763582703865, 1636.663975450278, -0.04643331697636249, 0.7615948374750167, -0.010397811196689507, -0.002202286738591026, -4.287589186049892, 0., 0., 0.))\n",
    "params2 = np.array((6900.766178626993, 6919.0517432373235, 3055.9219427396583, 1659.8768050681379, -0.07241143420209739, 0.00311945599198001, -0.008597066196675609, 0.002601995972163532, 0.46863386164346776, 0., 0., 0.))\n",
    "\n",
    "camera1_dict = {\n",
    "    'model': model,\n",
    "    'width': width,\n",
    "    'height': height,\n",
    "    'params': params1\n",
    "}\n",
    "camera21_dict = {\n",
    "    'model': model,\n",
    "    'width': width,\n",
    "    'height': height,\n",
    "    'params': params2\n",
    "}\n",
    "\n",
    "camera_id1 = db.add_camera(model, width, height, params1)\n",
    "camera_id2 = db.add_camera(model, width, height, params2)\n",
    "\n",
    "# Create images.\n",
    "image_id1 = db.add_image(\"image1.png\", camera_id1)\n",
    "image_id2 = db.add_image(\"image2.png\", camera_id2)\n",
    "\n",
    "# Create dummy keypoints.\n",
    "# Note that COLMAP supports:\n",
    "#      - 2D keypoints: (x, y)\n",
    "#      - 4D keypoints: (x, y, theta, scale)\n",
    "#      - 6D affine keypoints: (x, y, a_11, a_12, a_21, a_22)\n",
    "\n",
    "num_keypoints = 1000\n",
    "keypoints1 = np.random.rand(num_keypoints, 2) * (width1, height1)\n",
    "keypoints2 = np.random.rand(num_keypoints, 2) * (width1, height1)\n",
    "db.add_keypoints(image_id1, keypoints1)\n",
    "db.add_keypoints(image_id2, keypoints2)\n",
    "\n",
    "# Create dummy matches.\n",
    "M = 50\n",
    "matches12 = np.random.randint(num_keypoints, size=(M, 2))\n",
    "matches23 = np.random.randint(num_keypoints, size=(M, 2))\n",
    "matches34 = np.random.randint(num_keypoints, size=(M, 2))\n",
    "db.add_matches(image_id1, image_id2, matches12)\n",
    "\n",
    "# Commit the data to the file.\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f09641-884d-4fa6-b67f-76dd6c4daa4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from database import (blob_to_array, image_ids_to_pair_id)\n",
    "\n",
    "# Read and check cameras.\n",
    "rows = db.execute(\"SELECT * FROM cameras\")\n",
    "camera_id, model, width, height, params, prior = next(rows)\n",
    "params = blob_to_array(params, np.float64)\n",
    "assert camera_id == camera_id1\n",
    "assert model == model1 and width == width1 and height == height1\n",
    "assert np.allclose(params, params1)\n",
    "\n",
    "camera_id, model, width, height, params, prior = next(rows)\n",
    "params = blob_to_array(params, np.float64)\n",
    "assert camera_id == camera_id2\n",
    "assert model == model2 and width == width2 and height == height2\n",
    "assert np.allclose(params, params2)\n",
    "\n",
    "# Read and check keypoints.\n",
    "keypoints = dict(\n",
    "    (image_id, blob_to_array(data, np.float32, (-1, 2)))\n",
    "    for image_id, data in db.execute(\n",
    "        \"SELECT image_id, data FROM keypoints\"))\n",
    "assert np.allclose(keypoints[image_id1], keypoints1)\n",
    "assert np.allclose(keypoints[image_id2], keypoints2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78c988e-8f5d-4eb9-9fb3-30b60810ae7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pair_id, data in db.execute(\"SELECT pair_id, data FROM matches\"):\n",
    "    print(pair_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f86281-82b3-4930-9b56-ca8ea5270312",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from database import (blob_to_array, image_ids_to_pair_id, pair_id_to_image_ids)\n",
    "\n",
    "\n",
    "# Read and check matches.\n",
    "pair_ids = [image_ids_to_pair_id(image_id1, image_id2)]\n",
    "\n",
    "matches = dict(\n",
    "    (pair_id_to_image_ids(pair_id),\n",
    "     blob_to_array(data, np.uint32, (-1, 2)))\n",
    "    for pair_id, data in db.execute(\"SELECT pair_id, data FROM matches\")\n",
    ")\n",
    "\n",
    "assert np.all(matches[(image_id1, image_id2)] == matches12)\n",
    "\n",
    "# Clean up.\n",
    "db.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b51ba3-dc76-4ecc-bf8b-85c469b64897",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b666c978-c2be-402c-9130-c378c2bdb4bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d70abd-62f8-483b-8c57-05e4c39bd884",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
