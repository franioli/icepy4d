{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first set up the python environment and define the configuration file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "# Import required standard modules\n",
    "import shutil\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Import required icepy4d4D modules\n",
    "from icepy4d import classes as icepy4d_classes\n",
    "from icepy4d.classes.epoch import Epoch, Epoches\n",
    "from icepy4d import matching\n",
    "from icepy4d import sfm\n",
    "from icepy4d import io\n",
    "from icepy4d import utils as icepy4d_utils\n",
    "from icepy4d.metashape import metashape as MS\n",
    "from icepy4d.utils import initialization as inizialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the configuration file\n",
    "CFG_FILE = \"config/config_2022.yaml\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inizialize all the required variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================\n",
      "ICEpy4D\n",
      "Image-based Continuos monitoring of glaciers' Evolution with low-cost stereo-cameras and Deep Learning photogrammetry\n",
      "2023 - Francesco Ioli - francesco.ioli@polimi.it\n",
      "================================================================\n",
      "\n",
      "\u001b[0;37m2023-08-29 18:38:13 | [INFO    ] Configuration file: config_2022\u001b[0m\n",
      "\u001b[0;37m2023-08-29 18:38:13 | [INFO    ] Epoch_to_process set to a pair of values. Expanding it for a range of epoches from epoch 0 to 158.\u001b[0m\n",
      "\u001b[0;37m2023-08-29 18:38:13 | [INFO    ] Image datastores created successfully.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Parse the configuration file\n",
    "cfg_file = Path(CFG_FILE)\n",
    "cfg = inizialization.parse_cfg(cfg_file)\n",
    "\n",
    "# Initialize the timer and logger\n",
    "timer_global = icepy4d_utils.AverageTimer()\n",
    "logger = icepy4d_utils.get_logger()\n",
    "\n",
    "# Get the list of cameras from the configuration file\n",
    "cams = cfg.cams\n",
    "\n",
    "# Get the list of images from the configuration file\n",
    "images, epoch_dict = inizialization.initialize_image_ds(cfg)\n",
    "\n",
    "# Initialize an empty Epoches object to store the results of each epoch\n",
    "epoches = Epoches(starting_epoch=cfg.proc.epoch_to_process[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stereo Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The stereo processing is carried out for each epoch in order to find matched features, estimating camera pose, and triangulating the 3D points. \n",
    "The output of this step is a set of 3D points and their corresponding descriptors.\n",
    "\n",
    "The processing for all the epoches is then iterated in a big loop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load or create a new Epoch object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a timer to measure the processing time\n",
    "timer = icepy4d_utils.AverageTimer()\n",
    "\n",
    "# Get epoch id to process\n",
    "ep = cfg.proc.epoch_to_process[0]\n",
    "\n",
    "# Define paths to the epoch directory\n",
    "epoch_name = epoch_dict[ep]\n",
    "epochdir = cfg.paths.results_dir / epoch_name\n",
    "\n",
    "# Load an existing epoch or create a new one\n",
    "if cfg.proc.load_existing_results:\n",
    "    try:\n",
    "        # Load existing epcoh from pickle file\n",
    "        epoch = Epoch.read_pickle(epochdir / f\"{epoch_name}.pickle\")\n",
    "\n",
    "    except:\n",
    "        logger.error(\n",
    "            f\"Unable to load epoch {epoch_name} from pickle file. Creating new epoch...\"\n",
    "        )\n",
    "        epoch = inizialization.initialize_epoch(\n",
    "            cfg=cfg, images=images, epoch_id=ep, epoch_dir=epochdir\n",
    "        )\n",
    "\n",
    "else:\n",
    "    # Create new epoch object\n",
    "    epoch = inizialization.initialize_epoch(\n",
    "        cfg=cfg, images=images, epoch_id=ep, epoch_dir=epochdir\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature matching with SuperGlue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;37m2023-08-29 18:20:07 | [INFO    ] Running inference on device cuda\u001b[0m\n",
      "Loaded SuperPoint model\n",
      "Loaded SuperGlue model (\"outdoor\" weights)\n",
      "\u001b[0;37m2023-08-29 18:20:07 | [INFO    ] Matching by tiles...\u001b[0m\n",
      "\u001b[0;37m2023-08-29 18:20:07 | [INFO    ] Matching tiles by preselection tile selection\u001b[0m\n",
      "\u001b[0;37m2023-08-29 18:20:08 | [INFO    ] Matching completed.\u001b[0m\n",
      "\u001b[0;37m2023-08-29 18:20:08 | [INFO    ]  - Matching tile pair (3, 2)\u001b[0m\n",
      "\u001b[0;37m2023-08-29 18:20:10 | [INFO    ]  - Matching tile pair (4, 7)\u001b[0m\n",
      "\u001b[0;37m2023-08-29 18:20:12 | [INFO    ]  - Matching tile pair (5, 7)\u001b[0m\n",
      "\u001b[0;37m2023-08-29 18:20:15 | [INFO    ]  - Matching tile pair (5, 8)\u001b[0m\n",
      "\u001b[0;37m2023-08-29 18:20:17 | [INFO    ]  - Matching tile pair (6, 6)\u001b[0m\n",
      "\u001b[0;37m2023-08-29 18:20:19 | [INFO    ]  - Matching tile pair (6, 9)\u001b[0m\n",
      "\u001b[0;37m2023-08-29 18:20:21 | [INFO    ]  - Matching tile pair (7, 6)\u001b[0m\n",
      "\u001b[0;37m2023-08-29 18:20:24 | [INFO    ]  - Matching tile pair (7, 7)\u001b[0m\n",
      "\u001b[0;37m2023-08-29 18:20:26 | [INFO    ]  - Matching tile pair (7, 9)\u001b[0m\n",
      "\u001b[0;37m2023-08-29 18:20:28 | [INFO    ]  - Matching tile pair (7, 10)\u001b[0m\n",
      "\u001b[0;37m2023-08-29 18:20:31 | [INFO    ]  - Matching tile pair (8, 7)\u001b[0m\n",
      "\u001b[0;37m2023-08-29 18:20:33 | [INFO    ]  - Matching tile pair (8, 8)\u001b[0m\n",
      "\u001b[0;37m2023-08-29 18:20:35 | [INFO    ]  - Matching tile pair (8, 10)\u001b[0m\n",
      "\u001b[0;37m2023-08-29 18:20:38 | [INFO    ]  - Matching tile pair (8, 11)\u001b[0m\n",
      "\u001b[0;37m2023-08-29 18:20:40 | [INFO    ]  - Matching tile pair (9, 9)\u001b[0m\n",
      "\u001b[0;37m2023-08-29 18:20:42 | [INFO    ]  - Matching tile pair (10, 9)\u001b[0m\n",
      "\u001b[0;37m2023-08-29 18:20:45 | [INFO    ]  - Matching tile pair (10, 10)\u001b[0m\n",
      "\u001b[0;37m2023-08-29 18:20:47 | [INFO    ]  - Matching tile pair (11, 10)\u001b[0m\n",
      "\u001b[0;37m2023-08-29 18:20:49 | [INFO    ] Restoring full image coordinates of matches...\u001b[0m\n",
      "\u001b[0;37m2023-08-29 18:20:49 | [INFO    ] Matching by tile completed.\u001b[0m\n",
      "\u001b[0;37m2023-08-29 18:20:49 | [INFO    ] Matching done!\u001b[0m\n",
      "\u001b[0;37m2023-08-29 18:20:49 | [INFO    ] Performing geometric verification...\u001b[0m\n",
      "\u001b[0;37m2023-08-29 18:20:50 | [INFO    ] Pydegensac found 2102 inliers (38.21%)\u001b[0m\n",
      "\u001b[0;37m2023-08-29 18:20:50 | [INFO    ] Geometric verification done.\u001b[0m\n",
      "\u001b[0;37m2023-08-29 18:20:51 | [INFO    ] [Timer] | [Matching] preselection=0.289, matching=41.784, geometric_verification=0.328, \u001b[0m\n",
      "Function match took 43.4364 seconds\n"
     ]
    }
   ],
   "source": [
    "# Define matching parameters\n",
    "matching_quality = matching.Quality.HIGH\n",
    "tile_selection = matching.TileSelection.PRESELECTION\n",
    "tiling_grid = [4, 3]\n",
    "tiling_overlap = 200\n",
    "geometric_verification = matching.GeometricVerification.PYDEGENSAC\n",
    "geometric_verification_threshold = 1\n",
    "geometric_verification_confidence = 0.9999\n",
    "match_dir = epoch.epoch_dir / \"matching\"\n",
    "\n",
    "# Create a new matcher object\n",
    "matcher = matching.SuperGlueMatcher(cfg.matching)\n",
    "matcher.match(\n",
    "    epoch.images[cams[0]].value,\n",
    "    epoch.images[cams[1]].value,\n",
    "    quality=matching_quality,\n",
    "    tile_selection=tile_selection,\n",
    "    grid=tiling_grid,\n",
    "    overlap=tiling_overlap,\n",
    "    do_viz_matches=True,\n",
    "    do_viz_tiles=False,\n",
    "    save_dir=match_dir,\n",
    "    geometric_verification=geometric_verification,\n",
    "    threshold=geometric_verification_threshold,\n",
    "    confidence=geometric_verification_confidence,\n",
    ")\n",
    "timer.update(\"matching\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the matched features from the Matcher object and save them in the current Epoch object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary with empty Features objects for each camera, which will be filled with the matched keypoints, descriptors and scores\n",
    "f = {cam: icepy4d_classes.Features() for cam in cams}\n",
    "\n",
    "# Stack matched keypoints, descriptors and scores into Features objects\n",
    "f[cams[0]].append_features_from_numpy(\n",
    "    x=matcher.mkpts0[:, 0],\n",
    "    y=matcher.mkpts0[:, 1],\n",
    "    descr=matcher.descriptors0,\n",
    "    scores=matcher.scores0,\n",
    ")\n",
    "f[cams[1]].append_features_from_numpy(\n",
    "    x=matcher.mkpts1[:, 0],\n",
    "    y=matcher.mkpts1[:, 1],\n",
    "    descr=matcher.descriptors1,\n",
    "    scores=matcher.scores1,\n",
    ")\n",
    "\n",
    "# Store the dictionary with the features in the Epoch object\n",
    "epoch.features = f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scene reconstruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, perform Relative orientation of the two cameras by using the matched features and the a-priori camera interior orientation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;37m2023-08-29 17:34:47 | [INFO    ] Relative Orientation - valid points: 1775/2018\u001b[0m\n",
      "\u001b[0;37m2023-08-29 17:34:47 | [INFO    ] Relative orientation Succeded.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Initialize RelativeOrientation class with a list containing the two\n",
    "# cameras and a list contaning the matched features location on each camera.\n",
    "relative_ori = sfm.RelativeOrientation(\n",
    "    [epoch.cameras[cams[0]], epoch.cameras[cams[1]]],\n",
    "    [\n",
    "        epoch.features[cams[0]].kpts_to_numpy(),\n",
    "        epoch.features[cams[1]].kpts_to_numpy(),\n",
    "    ],\n",
    ")\n",
    "relative_ori.estimate_pose(\n",
    "    threshold=cfg.matching.pydegensac_threshold,\n",
    "    confidence=0.999999,\n",
    "    scale_factor=np.linalg.norm(\n",
    "        cfg.georef.camera_centers_world[0] - cfg.georef.camera_centers_world[1]\n",
    "    ),\n",
    ")\n",
    "# Store result in camera 1 object\n",
    "epoch.cameras[cams[1]] = relative_ori.cameras[1]\n",
    "\n",
    "# Update timer\n",
    "timer.update(\"relative orientation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Triangulate points into the object space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;37m2023-08-29 17:34:37 | [INFO    ] Point triangulation succeded: 1.0.\u001b[0m\n",
      "\u001b[0;37m2023-08-29 17:34:37 | [INFO    ] Point colors interpolated\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "triang = sfm.Triangulate(\n",
    "    [epoch.cameras[cams[0]], epoch.cameras[cams[1]]],\n",
    "    [\n",
    "        epoch.features[cams[0]].kpts_to_numpy(),\n",
    "        epoch.features[cams[1]].kpts_to_numpy(),\n",
    "    ],\n",
    ")\n",
    "points3d = triang.triangulate_two_views(\n",
    "    compute_colors=True, image=images[cams[1]].read_image(ep).value, cam_id=1\n",
    ")\n",
    "\n",
    "# Update timer\n",
    "timer.update(\"triangulation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform an absolute orientation of the current solution (i.e., cameras' exterior orientation and 3D points) by using the ground control points.\n",
    "\n",
    "The coordinates of the two cameras are used as additional ground control points for estimating a Helmert transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m2023-08-29 17:34:18 | [WARNING ] Warning: target T2 is not present on camera 0.\u001b[0m\n",
      "\u001b[1;33m2023-08-29 17:34:18 | [WARNING ] Warning: target F10_2 is not present on camera 0.\u001b[0m\n",
      "\u001b[1;33m2023-08-29 17:34:18 | [WARNING ] Warning: target T2 is not present on camera 1.\u001b[0m\n",
      "\u001b[1;33m2023-08-29 17:34:18 | [WARNING ] Warning: target F10_2 is not present on camera 1.\u001b[0m\n",
      "\u001b[1;33m2023-08-29 17:34:18 | [WARNING ] Not all targets found. Using onlys ['F2', 'F12', 'F13']\u001b[0m\n",
      "\u001b[0;37m2023-08-29 17:34:18 | [INFO    ] Point triangulation succeded: 1.0.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Get targets available in all cameras. The Labels of valid targets are returned as second element by the get_image_coor_by_label() method\n",
    "valid_targets = epoch.targets.get_image_coor_by_label(\n",
    "    cfg.georef.targets_to_use, cam_id=0\n",
    ")[1]\n",
    "\n",
    "# Check if the same targets are available in all cameras\n",
    "for id in range(1, len(cams)):\n",
    "    assert (\n",
    "        valid_targets\n",
    "        == epoch.targets.get_image_coor_by_label(\n",
    "            cfg.georef.targets_to_use, cam_id=id\n",
    "        )[1]\n",
    "    ), f\"\"\"epoch {ep} - {epoch_dict[ep]}: \n",
    "    Different targets found in image {id} - {images[cams[id]][ep]}\"\"\"\n",
    "\n",
    "# Check if there are enough targets\n",
    "assert len(valid_targets) > 1, f\"Not enough targets found in epoch {ep}\"\n",
    "\n",
    "# If not all the targets defined in the config file are found, log a warning and use only the valid targets\n",
    "if valid_targets != cfg.georef.targets_to_use:\n",
    "    logger.warning(f\"Not all targets found. Using onlys {valid_targets}\")\n",
    "\n",
    "# Get image and object coordinates of valid targets\n",
    "image_coords = [\n",
    "    epoch.targets.get_image_coor_by_label(valid_targets, cam_id=id)[0]\n",
    "    for id, cam in enumerate(cams)\n",
    "]\n",
    "obj_coords = epoch.targets.get_object_coor_by_label(valid_targets)[0]\n",
    "\n",
    "# Perform absolute orientation\n",
    "abs_ori = sfm.Absolute_orientation(\n",
    "    (epoch.cameras[cams[0]], epoch.cameras[cams[1]]),\n",
    "    points3d_final=obj_coords,\n",
    "    image_points=image_coords,\n",
    "    camera_centers_world=cfg.georef.camera_centers_world,\n",
    ")\n",
    "T = abs_ori.estimate_transformation_linear(estimate_scale=True)\n",
    "points3d = abs_ori.apply_transformation(points3d=points3d)\n",
    "for i, cam in enumerate(cams):\n",
    "    epoch.cameras[cam] = abs_ori.cameras[i]\n",
    "\n",
    "# Convert the 3D points to an icepy4d Points object\n",
    "pts = icepy4d_classes.Points()\n",
    "pts.append_points_from_numpy(\n",
    "    points3d,\n",
    "    track_ids=epoch.features[cams[0]].get_track_ids(),\n",
    "    colors=triang.colors,\n",
    ")\n",
    "\n",
    "# Store the points in the Epoch object\n",
    "epoch.points = pts\n",
    "\n",
    "# Update timer\n",
    "timer.update(\"absolute orientation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the current Epoch object as a pickle file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;37m2023-08-29 18:32:30 | [INFO    ] 2022-05-01_14:01:15 saved successfully\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Save epoch as a pickle object\n",
    "if epoch.save_pickle(f\"{epoch.epoch_dir}/{epoch}.pickle\"):\n",
    "    logger.info(f\"{epoch} saved successfully\")\n",
    "else:\n",
    "    logger.error(f\"Unable to save {epoch}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Big loop over the epoches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stack all the processing of a single epoch into a function and iterate over all the epoches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define processing for single epoch\n",
    "def process_epoch(epoch, cfg, timer) -> Epoch:\n",
    "\n",
    "    cams = cfg.cams\n",
    "    epochdir = epoch.epoch_dir\n",
    "    match_dir = epochdir / \"matching\"\n",
    "   \n",
    "    # Matching\n",
    "    matching_quality = matching.Quality.HIGH\n",
    "    tile_selection = matching.TileSelection.PRESELECTION\n",
    "    tiling_grid = [4, 3]\n",
    "    tiling_overlap = 200\n",
    "    geometric_verification = matching.GeometricVerification.PYDEGENSAC\n",
    "    geometric_verification_threshold = 1\n",
    "    geometric_verification_confidence = 0.9999\n",
    "    matcher = matching.SuperGlueMatcher(cfg.matching)    \n",
    "    matcher.match(\n",
    "        epoch.images[cams[0]].value,\n",
    "        epoch.images[cams[1]].value,\n",
    "        quality=matching_quality,\n",
    "        tile_selection=tile_selection,\n",
    "        grid=tiling_grid,\n",
    "        overlap=tiling_overlap,\n",
    "        do_viz_matches=True,\n",
    "        do_viz_tiles=False,\n",
    "        save_dir=match_dir,\n",
    "        geometric_verification=geometric_verification,\n",
    "        threshold=geometric_verification_threshold,\n",
    "        confidence=geometric_verification_confidence,\n",
    "    )\n",
    "    f = {cam: icepy4d_classes.Features() for cam in cams}\n",
    "    f[cams[0]].append_features_from_numpy(\n",
    "        x=matcher.mkpts0[:, 0],\n",
    "        y=matcher.mkpts0[:, 1],\n",
    "        descr=matcher.descriptors0,\n",
    "        scores=matcher.scores0,\n",
    "    )\n",
    "    f[cams[1]].append_features_from_numpy(\n",
    "        x=matcher.mkpts1[:, 0],\n",
    "        y=matcher.mkpts1[:, 1],\n",
    "        descr=matcher.descriptors1,\n",
    "        scores=matcher.scores1,\n",
    "    )\n",
    "    epoch.features = f\n",
    "    timer.update(\"matching\")\n",
    "    \n",
    "    # Relative orientation\n",
    "    relative_ori = sfm.RelativeOrientation(\n",
    "    [epoch.cameras[cams[0]], epoch.cameras[cams[1]]],\n",
    "    [\n",
    "        epoch.features[cams[0]].kpts_to_numpy(),\n",
    "        epoch.features[cams[1]].kpts_to_numpy(),\n",
    "    ],\n",
    "    )\n",
    "    relative_ori.estimate_pose(\n",
    "    threshold=cfg.matching.pydegensac_threshold,\n",
    "    confidence=0.999999,\n",
    "    scale_factor=np.linalg.norm(\n",
    "        cfg.georef.camera_centers_world[0] - cfg.georef.camera_centers_world[1]\n",
    "    ),\n",
    "    )\n",
    "    epoch.cameras[cams[1]] = relative_ori.cameras[1]\n",
    "    timer.update(\"relative orientation\")\n",
    "\n",
    "    # Triangulation\n",
    "    triang = sfm.Triangulate(\n",
    "        [epoch.cameras[cams[0]], epoch.cameras[cams[1]]],\n",
    "        [\n",
    "            epoch.features[cams[0]].kpts_to_numpy(),\n",
    "            epoch.features[cams[1]].kpts_to_numpy(),\n",
    "        ],\n",
    "    )\n",
    "    points3d = triang.triangulate_two_views(\n",
    "        compute_colors=True, image=images[cams[1]].read_image(ep).value, cam_id=1\n",
    "    )\n",
    "    timer.update(\"triangulation\")    \n",
    "\n",
    "    # Absolute orientation\n",
    "    valid_targets = epoch.targets.get_image_coor_by_label(\n",
    "        cfg.georef.targets_to_use, cam_id=0\n",
    "    )[1]\n",
    "    for id in range(1, len(cams)):\n",
    "        assert (\n",
    "            valid_targets\n",
    "            == epoch.targets.get_image_coor_by_label(\n",
    "                cfg.georef.targets_to_use, cam_id=id\n",
    "            )[1]\n",
    "        ), f\"\"\"epoch {ep} - {epoch_dict[ep]}: \n",
    "        Different targets found in image {id} - {images[cams[id]][ep]}\"\"\"\n",
    "    assert len(valid_targets) > 1, f\"Not enough targets found in epoch {ep}\"\n",
    "    if valid_targets != cfg.georef.targets_to_use:\n",
    "        logger.warning(f\"Not all targets found. Using onlys {valid_targets}\")\n",
    "\n",
    "    image_coords = [\n",
    "        epoch.targets.get_image_coor_by_label(valid_targets, cam_id=id)[0]\n",
    "        for id, cam in enumerate(cams)\n",
    "    ]\n",
    "    obj_coords = epoch.targets.get_object_coor_by_label(valid_targets)[0]\n",
    "\n",
    "    abs_ori = sfm.Absolute_orientation(\n",
    "        (epoch.cameras[cams[0]], epoch.cameras[cams[1]]),\n",
    "        points3d_final=obj_coords,\n",
    "        image_points=image_coords,\n",
    "        camera_centers_world=cfg.georef.camera_centers_world,\n",
    "    )\n",
    "    T = abs_ori.estimate_transformation_linear(estimate_scale=True)\n",
    "    points3d = abs_ori.apply_transformation(points3d=points3d)\n",
    "    for i, cam in enumerate(cams):\n",
    "        epoch.cameras[cam] = abs_ori.cameras[i]\n",
    "\n",
    "    pts = icepy4d_classes.Points()\n",
    "    pts.append_points_from_numpy(\n",
    "        points3d,\n",
    "        track_ids=epoch.features[cams[0]].get_track_ids(),\n",
    "        colors=triang.colors,\n",
    "    )\n",
    "    epoch.points = pts\n",
    "    timer.update(\"absolute orientation\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;37m2023-08-29 18:36:01 | [INFO    ] Running inference on device cuda\u001b[0m\n",
      "Loaded SuperPoint model\n",
      "Loaded SuperGlue model (\"outdoor\" weights)\n",
      "\u001b[0;37m2023-08-29 18:36:03 | [INFO    ] Matching by tiles...\u001b[0m\n",
      "\u001b[0;37m2023-08-29 18:36:03 | [INFO    ] Matching tiles by preselection tile selection\u001b[0m\n",
      "\u001b[0;37m2023-08-29 18:36:03 | [INFO    ] Matching completed.\u001b[0m\n",
      "\u001b[0;37m2023-08-29 18:36:03 | [INFO    ]  - Matching tile pair (3, 2)\u001b[0m\n",
      "\u001b[0;37m2023-08-29 18:36:06 | [INFO    ]  - Matching tile pair (4, 7)\u001b[0m\n",
      "\u001b[0;37m2023-08-29 18:36:08 | [INFO    ]  - Matching tile pair (5, 7)\u001b[0m\n",
      "\u001b[0;37m2023-08-29 18:36:10 | [INFO    ]  - Matching tile pair (5, 8)\u001b[0m\n",
      "\u001b[0;37m2023-08-29 18:36:13 | [INFO    ]  - Matching tile pair (6, 6)\u001b[0m\n",
      "\u001b[0;37m2023-08-29 18:36:15 | [INFO    ]  - Matching tile pair (6, 9)\u001b[0m\n",
      "\u001b[0;37m2023-08-29 18:36:17 | [INFO    ]  - Matching tile pair (7, 6)\u001b[0m\n",
      "\u001b[0;37m2023-08-29 18:36:20 | [INFO    ]  - Matching tile pair (7, 7)\u001b[0m\n",
      "\u001b[0;37m2023-08-29 18:36:22 | [INFO    ]  - Matching tile pair (7, 9)\u001b[0m\n",
      "\u001b[0;37m2023-08-29 18:36:24 | [INFO    ]  - Matching tile pair (7, 10)\u001b[0m\n",
      "\u001b[0;37m2023-08-29 18:36:27 | [INFO    ]  - Matching tile pair (8, 7)\u001b[0m\n",
      "\u001b[0;37m2023-08-29 18:36:29 | [INFO    ]  - Matching tile pair (8, 8)\u001b[0m\n",
      "\u001b[0;37m2023-08-29 18:36:31 | [INFO    ]  - Matching tile pair (8, 10)\u001b[0m\n",
      "\u001b[0;37m2023-08-29 18:36:34 | [INFO    ]  - Matching tile pair (8, 11)\u001b[0m\n",
      "\u001b[0;37m2023-08-29 18:36:36 | [INFO    ]  - Matching tile pair (9, 9)\u001b[0m\n",
      "\u001b[0;37m2023-08-29 18:36:38 | [INFO    ]  - Matching tile pair (10, 9)\u001b[0m\n",
      "\u001b[0;37m2023-08-29 18:36:41 | [INFO    ]  - Matching tile pair (10, 10)\u001b[0m\n",
      "\u001b[0;37m2023-08-29 18:36:43 | [INFO    ]  - Matching tile pair (11, 10)\u001b[0m\n",
      "\u001b[0;37m2023-08-29 18:36:45 | [INFO    ] Restoring full image coordinates of matches...\u001b[0m\n",
      "\u001b[0;37m2023-08-29 18:36:45 | [INFO    ] Matching by tile completed.\u001b[0m\n",
      "\u001b[0;37m2023-08-29 18:36:45 | [INFO    ] Matching done!\u001b[0m\n",
      "\u001b[0;37m2023-08-29 18:36:45 | [INFO    ] Performing geometric verification...\u001b[0m\n",
      "\u001b[0;37m2023-08-29 18:36:46 | [INFO    ] Pydegensac found 2041 inliers (37.10%)\u001b[0m\n",
      "\u001b[0;37m2023-08-29 18:36:46 | [INFO    ] Geometric verification done.\u001b[0m\n",
      "\u001b[0;37m2023-08-29 18:36:47 | [INFO    ] [Timer] | [Matching] preselection=0.938, matching=41.925, geometric_verification=0.384, \u001b[0m\n",
      "Function match took 44.2175 seconds\n",
      "\u001b[0;37m2023-08-29 18:36:47 | [INFO    ] Relative Orientation - valid points: 1907/2041\u001b[0m\n",
      "\u001b[0;37m2023-08-29 18:36:47 | [INFO    ] Relative orientation Succeded.\u001b[0m\n",
      "\u001b[0;37m2023-08-29 18:36:47 | [INFO    ] Point triangulation succeded: 1.0.\u001b[0m\n",
      "\u001b[0;37m2023-08-29 18:36:47 | [INFO    ] Point colors interpolated\u001b[0m\n",
      "\u001b[1;33m2023-08-29 18:36:47 | [WARNING ] Warning: target T2 is not present on camera 0.\u001b[0m\n",
      "\u001b[1;33m2023-08-29 18:36:47 | [WARNING ] Warning: target F10_2 is not present on camera 0.\u001b[0m\n",
      "\u001b[1;33m2023-08-29 18:36:47 | [WARNING ] Warning: target T2 is not present on camera 1.\u001b[0m\n",
      "\u001b[1;33m2023-08-29 18:36:47 | [WARNING ] Warning: target F10_2 is not present on camera 1.\u001b[0m\n",
      "\u001b[1;33m2023-08-29 18:36:47 | [WARNING ] Not all targets found. Using onlys ['F2', 'F12', 'F13']\u001b[0m\n",
      "\u001b[0;37m2023-08-29 18:36:47 | [INFO    ] Point triangulation succeded: 1.0.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "epoch = inizialization.initialize_epoch(\n",
    "    cfg=cfg, images=images, epoch_id=ep, epoch_dir=epochdir\n",
    "    )\n",
    "process_epoch(epoch, cfg, timer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add epoch to epoches object\n",
    "epoches.add_epoch(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"------------------------------------------------------\")\n",
    "logger.info(\"Processing started:\")\n",
    "timer = icepy4d_utils.AverageTimer()\n",
    "iter = 0  # necessary only for printing the number of processed iteration\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icepy4d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
