{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.dates import DayLocator, DateFormatter\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "%matplotlib widget\n",
    "\n",
    "PCD_DIR = \"res/point_clouds_meshed\"\n",
    "PCD_PATTERN = \"sampled*.ply\"\n",
    "OUT_DIR = \"res/volumes_variations\"\n",
    "DOD_DIR = \"x\"\n",
    "TSTEP = 5\n",
    "GRID_STEP = 0.3\n",
    "TEMPERATURE_FILE = \"res/temperature_data/temperature_zamboni.csv\"\n",
    "# SURF_VEL_FILE = \"res/surface_velocities/TS_punto-fronte.txt\"\n",
    "SURF_VEL_FILE = \"res/surface_velocities/TS_punto-corpo.txt\"\n",
    "\n",
    "icepy_dir = Path.cwd().parents[1]\n",
    "\n",
    "# Paths\n",
    "pcd_dir = icepy_dir / Path(PCD_DIR)\n",
    "out_dir = icepy_dir / Path(OUT_DIR)\n",
    "temp_path = icepy_dir / Path(TEMPERATURE_FILE)\n",
    "\n",
    "# Output file\n",
    "fout_name = (\n",
    "    f\"{PCD_PATTERN.split('*')[0]}_dir{DOD_DIR.upper()}_tstep{TSTEP}_grid{GRID_STEP}\"\n",
    ")\n",
    "fout = out_dir / f\"{fout_name}.csv\"\n",
    "\n",
    "# import matplotlib.dates as mdates\n",
    "dateFmt = DateFormatter('%b')\n",
    "\n",
    "# Read volume results from file\n",
    "column_names = [\n",
    "    \"pcd0\",\n",
    "    \"pcd1\",\n",
    "    \"volume\",\n",
    "    \"addedVolume\",\n",
    "    \"removedVolume\",\n",
    "    \"surface\",\n",
    "    \"matchingPercent\",\n",
    "    \"averageNeighborsPerCell\",\n",
    "]\n",
    "df = pd.read_csv(fout, sep=\",\", names=column_names)\n",
    "\n",
    "\n",
    "# Build date index, sort dataframe and compute dt\n",
    "max_surface_match = df[\"matchingPercent\"].to_numpy().max()\n",
    "df[\"date_in\"] = pd.to_datetime(\n",
    "    df[\"pcd0\"].str.replace(f\"{PCD_PATTERN.split('*')[0]}_\", \"\"), format=\"%Y_%m_%d\"\n",
    ")\n",
    "df.sort_values(by=\"date_in\", inplace=True)\n",
    "\n",
    "df[\"date_fin\"] = pd.to_datetime(\n",
    "    df[\"pcd1\"].str.replace(f\"{PCD_PATTERN.split('*')[0]}_\", \"\"), format=\"%Y_%m_%d\"\n",
    ")\n",
    "df[\"dt\"] = (df.date_fin - df.date_in) / np.timedelta64(1, \"D\")\n",
    "\n",
    "# Compute daily volume variation and normalize by area\n",
    "df[\"volume_daily\"] = df[\"volume\"] / df[\"dt\"]\n",
    "df[\"volume_daily_normalized\"] = (\n",
    "    df[\"volume_daily\"] / df[\"matchingPercent\"] * max_surface_match\n",
    ")\n",
    "\n",
    "# Compute cumulated volumes\n",
    "df[\"volume_daily_cumul\"] = df[\"volume_daily\"].cumsum()\n",
    "df[\"volume_daily_norm_cumul\"] = df[\"volume_daily_normalized\"].cumsum()\n",
    "\n",
    "\n",
    "# Read temperature data\n",
    "temp_df = pd.read_csv(temp_path, sep=\",\")\n",
    "temp_df[\"data\"] = pd.to_datetime(temp_df[\"data\"], format=\"%d/%m/%Y\")\n",
    "\n",
    "start_date = df[\"date_in\"].min()\n",
    "end_date = df[\"date_fin\"].max()\n",
    "\n",
    "mask = (temp_df['data'] >= start_date) & (temp_df['data'] <= end_date)\n",
    "temp_df = temp_df.loc[mask] \n",
    "\n",
    "# Compute rolling average of the temperature time series on a fixed time windows of 5 days, with the value at the center of the time window\n",
    "time_window = 5\n",
    "temp_df[\"Tavg_5d\"] = temp_df[\"Tmed\"] .rolling(time_window, min_periods=5, center=True).mean()\n",
    "\n",
    "# Read surface velocities\n",
    "temp_path = icepy_dir / Path(SURF_VEL_FILE)\n",
    "\n",
    "surf_df = pd.read_csv(temp_path, sep=\",\")\n",
    "surf_df[\"t1\"] = pd.to_datetime(surf_df[\"t1\"], format='%d-%b-%Y')\n",
    "surf_df[\"t2\"] = pd.to_datetime(surf_df[\"t2\"], format='%d-%b-%Y')\n",
    "\n",
    "\n",
    "# Define days for plotting: Each point of the volume time series is plotted at the middle of the time window\n",
    "df[\"day_plot\"] = df[\"date_in\"] + (df[\"date_fin\"] - df[\"date_in\"]) /2\n",
    "df.sort_values(by=\"date_in\", inplace=True)\n",
    "temp_df[\"day_plot\"] = temp_df[\"data\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export pandas dataframes to csv for computing rloess smoothing\n",
    "df_out_dir = \"res/surface_velocities\"\n",
    "df_out_dir = icepy_dir = Path.cwd().parents[1] / df_out_dir\n",
    "\n",
    "volumes_df = df[[\"date_in\",\"date_fin\",\"dt\", \"day_plot\", \"volume_daily_normalized\", \"volume_daily_norm_cumul\"]]\n",
    "volumes_df.sort_values(by=\"date_in\", inplace=True)\n",
    "volumes_df.to_csv(df_out_dir / f\"volumes_processed.csv\", index=False)\n",
    "temp_df.to_csv(df_out_dir / f\"temperature_processed.csv\", index=False)\n",
    "surf_df.to_csv(df_out_dir / f\"surface_velocities_processed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read smoothed time series\n",
    "df_out_dir = \"res/surface_velocities\"\n",
    "df_out_dir = icepy_dir = Path.cwd().parents[1] / df_out_dir\n",
    "\n",
    "V_rloess = np.reshape(np.loadtxt(df_out_dir / f\"volume_daily_rloess.csv\", delimiter=\",\"), -1)\n",
    "T_rloess = np.reshape(np.loadtxt(df_out_dir / f\"temp_rloess.csv\", delimiter=\",\"), -1)\n",
    "\n",
    "df[\"volume_daily_norm_rloess\"] = V_rloess\n",
    "temp_df[\"Tavg_5d_rloess\"] = T_rloess\n",
    "\n",
    "\n",
    "# Export pandas dataframes to csv\n",
    "df_out_dir = \"res/surface_velocities\"\n",
    "df_out_dir = icepy_dir = Path.cwd().parents[1] / df_out_dir\n",
    "\n",
    "volumes_df = df[[\"date_in\",\"date_fin\",\"dt\", \"day_plot\", \"volume_daily_normalized\", \"volume_daily_norm_cumul\", \"volume_daily_norm_rloess\"]]\n",
    "volumes_df.sort_values(by=\"date_in\", inplace=True)\n",
    "volumes_df.to_csv(df_out_dir / f\"volumes_processed.csv\", index=False)\n",
    "temeratures_df = temp_df[[\"data\", \"day_plot\", \"Tavg_5d\", \"Tavg_5d_rloess\"]]\n",
    "temeratures_df.to_csv(df_out_dir / f\"temperature_processed.csv\", index=False)\n",
    "surf_df.to_csv(df_out_dir / f\"surface_velocities_processed.csv\", index=False)\n",
    "\n",
    "\n",
    "# Export to parquet dataframes\n",
    "volumes_df.to_parquet(df_out_dir / f\"volumes_processed.parquet\", index=False)\n",
    "temeratures_df.to_parquet(df_out_dir / f\"temperature_processed.parquet\", index=False)\n",
    "surf_df.to_parquet(df_out_dir / f\"surface_velocities_processed.parquet\", index=False)\n",
    "\n",
    "# Create new df with\n",
    "temp_valid = pd.merge(temp_df, df, left_on=\"data\", right_on=\"date_in\", how=\"right\")\n",
    "temp_valid = temp_valid[[\"data\", \"day_plot_x\", \"Tavg_5d\", \"Tavg_5d_rloess\"]]\n",
    "temp_valid.to_csv(df_out_dir / f\"temperature_processed_validday.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make plot for Daily volumes\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_tight_layout(True)\n",
    "ax.grid(visible=True, which=\"both\")\n",
    "ax.plot(df[\"date_in\"], -df[\"volume_daily_normalized\"])\n",
    "ax.set_xlabel(\"Date\")\n",
    "ax.xaxis.set_major_formatter(dateFmt)\n",
    "ax.set_ylabel(\"-dV [$m^3$]\")\n",
    "ax.set_title(f\"Daily volume differences\")\n",
    "ax.minorticks_on()\n",
    "ax.grid(which=\"major\", axis=\"y\", linewidth=0.5, color=\"black\")\n",
    "ax.grid(which=\"major\", axis=\"x\", linewidth=0.3, color=\"black\")\n",
    "ax.grid(which=\"minor\", axis=\"y\", linestyle=\":\", linewidth=0.5, color=\"black\")\n",
    "ax.grid(which=\"minor\", axis=\"x\", linestyle=\":\", linewidth=0.3, color=\"black\")\n",
    "ax.xaxis.set_minor_locator(\n",
    "    DayLocator(bymonthday=[7, 14, 21, 28], interval=1, tz=None)\n",
    ")\n",
    "# fig.set_size_inches(18.5, 10.5)\n",
    "# fig.savefig(out_dir / f\"{fout_name}_daily_diff_norm.png\", dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot only volume-temperatures\n",
    "\n",
    "# Create host and parasite subplots\n",
    "fig, host = plt.subplots(figsize=(10, 6))\n",
    "par = host.twinx()\n",
    "\n",
    "# Create temperature and volume plots\n",
    "p1, = host.plot(temp_df[\"day_plot\"], temp_df[\"Tavg_5d\"], label=\"Temperature\", linewidth=1, color=\"tab:blue\")\n",
    "p2, = par.plot(df[\"day_plot\"], -df[\"volume_daily_normalized\"], label=\"Volume\", linewidth=1, color=\"tab:red\")\n",
    "\n",
    "# Set x and y labels\n",
    "host.set_xlabel(\"Date\", fontsize=12)\n",
    "host.set_ylabel(\"Temperature [$^{\\circ}$C]\", fontsize=12, color=\"tab:blue\")\n",
    "par.set_ylabel(\"Daily volume loss [$m^3/d$]\", fontsize=12, color=\"tab:red\")\n",
    "\n",
    "# Set x-axis date format\n",
    "dateFmt = DateFormatter('%b')\n",
    "host.xaxis.set_major_formatter(dateFmt)\n",
    "\n",
    "# Set grid lines\n",
    "host.grid(which=\"both\", linestyle=\"--\", alpha=0.5)\n",
    "host.grid(which=\"major\", axis=\"y\", linewidth=0.5, color=\"black\")\n",
    "host.grid(which=\"major\", axis=\"x\", linewidth=0.5, color=\"black\")\n",
    "host.xaxis.set_minor_locator(DayLocator(bymonthday=[7, 14, 21, 28], interval=1, tz=None))\n",
    "host.grid(which=\"minor\", axis=\"y\", linestyle=\":\", linewidth=0.5, color=\"black\")\n",
    "host.grid(which=\"minor\", axis=\"x\", linestyle=\":\", linewidth=0.5, color=\"black\")\n",
    "\n",
    "# Set legend\n",
    "lines = [p1, p2]\n",
    "labels = [line.get_label() for line in lines]\n",
    "host.legend(lines, labels, loc=\"upper left\", fontsize=12)\n",
    "\n",
    "# Set colors\n",
    "host.tick_params(axis=\"y\", labelcolor=\"tab:blue\")\n",
    "par.tick_params(axis=\"y\", labelcolor=\"tab:red\")\n",
    "host.yaxis.label.set_color(\"tab:blue\")\n",
    "par.yaxis.label.set_color(\"tab:red\")\n",
    "\n",
    "# Set title\n",
    "plt.title(f\"Temperature and Volume Loss (step {TSTEP} days)\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLD Test for rolling average\n",
    "# df[\"day_plot\"] = df[\"date_in\"] + np.timedelta64(5, \"D\") \n",
    "# df[\"day_plot\"] = df[\"date_in\"]\n",
    "# temp_df[\"day_plot\"] = temp_df[\"data\"]\n",
    "# temp_df[\"Tmed_5d\"] = temp_df[\"Tmed\"] .rolling(5, min_periods=1, center=False).mean()\n",
    "\n",
    "\n",
    "# Trying to manaully compute rolling average on the same time window as the volume (differs from a regular rolling average with fixed time window is almost negligible)\n",
    "\n",
    "# merged = pd.merge(temp_df, df, left_on=\"data\", right_on=\"date_in\", how=\"left\")\n",
    "# merged = merged[[\"data\", \"Tmed\", \"date_in\", \"date_fin\"]]\n",
    "\n",
    "# merged['rol_avg'] = np.nan\n",
    "# for i in range(len(merged[\"date_in\"])):\n",
    "#     if pd.isna(merged[\"date_in\"][i]):\n",
    "#         continue    \n",
    "#     d_in = merged[\"date_in\"][i]\n",
    "#     d_fin = merged[\"date_fin\"][i]\n",
    "#     mask = (merged['data'] >= d_in) & (merged['data'] < d_fin)\n",
    "#     avg = merged['Tmed'][mask].mean()\n",
    "#     merged['rol_avg'][i]  = avg\n",
    " \n",
    "# T_roll_avg = merged[[\"date_in\", \"date_fin\", \"rol_avg\"]][merged[\"date_in\"].notnull()]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "belpy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
