{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "Input parameters are valid.\n",
      "\n",
      "Image datastores created successfully.\n",
      "Processing epoch 0...\n",
      "Run Superglue to find matches at epoch 0\n",
      "Will not resize images\n",
      "Running inference on device \"cuda\"\n",
      "Loaded SuperPoint model\n",
      "Loaded SuperGlue model (\"outdoor\" weights)\n",
      "Will write matches to directory \"res/epoch_0\"\n",
      "Will write visualization images to directory \"res/epoch_0\"\n",
      "Warning: input resolution is very large, results may vary\n",
      "Warning: input resolution is very large, results may vary\n",
      "Images subdivided in 2x4 tiles\n",
      "[Finished Tile Pairs  0 -  0 of  8] matcher=6.096 viz_match=0.259 total=6.355 sec {0.2 FPS} \n",
      "[Finished Tile Pairs  1 -  1 of  8] matcher=5.678 viz_match=0.257 total=5.935 sec {0.2 FPS} \n",
      "[Finished Tile Pairs  2 -  2 of  8] matcher=5.018 viz_match=0.263 total=5.281 sec {0.2 FPS} \n",
      "[Finished Tile Pairs  3 -  3 of  8] matcher=4.912 viz_match=0.269 total=5.181 sec {0.2 FPS} \n",
      "[Finished Tile Pairs  4 -  4 of  8] matcher=4.267 viz_match=0.268 total=4.535 sec {0.2 FPS} \n",
      "[Finished Tile Pairs  5 -  5 of  8] matcher=4.384 viz_match=0.273 total=4.658 sec {0.2 FPS} \n",
      "[Finished Tile Pairs  6 -  6 of  8] matcher=4.402 viz_match=0.277 total=4.679 sec {0.2 FPS} \n",
      "[Finished Tile Pairs  7 -  7 of  8] matcher=4.504 viz_match=0.267 total=4.771 sec {0.2 FPS} \n",
      "[Finished pair] load_image=0.312 create_tiles=0.010 viz_match=38.933 total=39.255 sec {0.0 FPS} \n",
      "Matching at epoch 0: pydegensac found 3982             inliers (53.97%)\n",
      "Matching completed\n",
      "Processing epoch 1...\n",
      "Run Superglue to find matches at epoch 1\n",
      "Will not resize images\n",
      "Running inference on device \"cuda\"\n",
      "Loaded SuperPoint model\n",
      "Loaded SuperGlue model (\"outdoor\" weights)\n",
      "Will write matches to directory \"res/epoch_1\"\n",
      "Will write visualization images to directory \"res/epoch_1\"\n",
      "Warning: input resolution is very large, results may vary\n",
      "Warning: input resolution is very large, results may vary\n",
      "Images subdivided in 2x4 tiles\n",
      "[Finished Tile Pairs  0 -  0 of  8] matcher=4.131 viz_match=0.239 total=4.370 sec {0.2 FPS} \n",
      "[Finished Tile Pairs  1 -  1 of  8] matcher=4.316 viz_match=0.240 total=4.555 sec {0.2 FPS} \n",
      "[Finished Tile Pairs  2 -  2 of  8] matcher=3.903 viz_match=0.243 total=4.146 sec {0.2 FPS} \n",
      "[Finished Tile Pairs  3 -  3 of  8] matcher=4.138 viz_match=0.250 total=4.388 sec {0.2 FPS} \n",
      "[Finished Tile Pairs  4 -  4 of  8] matcher=3.577 viz_match=0.252 total=3.829 sec {0.3 FPS} \n",
      "[Finished Tile Pairs  5 -  5 of  8] matcher=3.848 viz_match=0.256 total=4.104 sec {0.2 FPS} \n",
      "[Finished Tile Pairs  6 -  6 of  8] matcher=3.864 viz_match=0.258 total=4.122 sec {0.2 FPS} \n",
      "[Finished Tile Pairs  7 -  7 of  8] matcher=4.102 viz_match=0.248 total=4.350 sec {0.2 FPS} \n",
      "[Finished pair] load_image=0.299 create_tiles=0.011 viz_match=35.000 total=35.309 sec {0.0 FPS} \n",
      "Matching at epoch 1: pydegensac found 4799             inliers (58.09%)\n",
      "Matching completed\n"
     ]
    }
   ],
   "source": [
    "from lib.validate_inputs import validate\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pickle\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import pydegensac\n",
    "import open3d as o3d\n",
    "\n",
    "from pathlib import Path\n",
    "from easydict import EasyDict as edict\n",
    "\n",
    "from lib.classes import (Camera, Imageds, Features, Targets)\n",
    "from lib.config import parse_yaml_cfg\n",
    "from lib.sfm.two_view_geometry import Two_view_geometry, Single_camera_geometry\n",
    "from lib.sfm.triangulation import Triangulate\n",
    "from lib.match_pairs import match_pair\n",
    "from lib.track_matches import track_matches\n",
    "\n",
    "from lib.geometry import (project_points,\n",
    "                          compute_reprojection_error\n",
    "                          )\n",
    "from lib.utils import (build_dsm,\n",
    "                       generate_ortophoto,\n",
    "                       )\n",
    "from lib.point_clouds import (create_point_cloud,\n",
    "                              write_ply,\n",
    "                              )\n",
    "from lib.visualization import (display_point_cloud,\n",
    "                               display_pc_inliers,\n",
    "                               plot_features,\n",
    "                               plot_projections,\n",
    "                               )\n",
    "from lib.misc import (convert_to_homogeneous,\n",
    "                      convert_from_homogeneous,\n",
    "                      create_directory,\n",
    "                      )\n",
    "\n",
    "from thirdparty.transformations import affine_matrix_from_points\n",
    "\n",
    "# Parse options from yaml file\n",
    "cfg_file = 'config/config_base.yaml'\n",
    "cfg = parse_yaml_cfg(cfg_file)\n",
    "\n",
    "# Inizialize Variables\n",
    "cams = cfg.paths.cam_names\n",
    "features = dict.fromkeys(cams)  # @TODO: put this in an inizialization function\n",
    "\n",
    "# Create Image Datastore objects\n",
    "images = dict.fromkeys(cams)  # @TODO: put this in an inizialization function\n",
    "for cam in cams:\n",
    "    images[cam] = Imageds(cfg.paths.imdir / cam)\n",
    "\n",
    "cfg = validate(cfg, images)\n",
    "\n",
    "''' Perform matching and tracking '''\n",
    "# Load matching and tracking configurations\n",
    "with open(cfg.matching_cfg) as f:\n",
    "    opt_matching = edict(json.load(f))\n",
    "with open(cfg.tracking_cfg) as f:\n",
    "    opt_tracking = edict(json.load(f))\n",
    "\n",
    "# epoch = 0\n",
    "if cfg.proc.do_matching:\n",
    "    for cam in cams:\n",
    "        features[cam] = []\n",
    "\n",
    "    for epoch in cfg.proc.epoch_to_process:\n",
    "        print(f'Processing epoch {epoch}...')\n",
    "\n",
    "        # opt_matching = cfg.matching.copy()\n",
    "        epochdir = Path(cfg.paths.resdir) / f'epoch_{epoch}'\n",
    "\n",
    "        #-- Find Matches at current epoch --#\n",
    "        print(f'Run Superglue to find matches at epoch {epoch}')\n",
    "        opt_matching.output_dir = epochdir\n",
    "        pair = [\n",
    "            images[cams[0]].get_image_path(epoch),\n",
    "            images[cams[1]].get_image_path(epoch)\n",
    "        ]\n",
    "        # Call matching function\n",
    "        matchedPts, matchedDescriptors, matchedPtsScores = match_pair(\n",
    "            pair, cfg.images.bbox, opt_matching\n",
    "        )\n",
    "\n",
    "        # Store matches in features structure\n",
    "        for jj, cam in enumerate(cams):\n",
    "            # Dict keys are the cameras names, internal list contain epoches\n",
    "            features[cam].append(Features())\n",
    "            features[cam][epoch].append_features({\n",
    "                'kpts': matchedPts[jj],\n",
    "                'descr': matchedDescriptors[jj],\n",
    "                'score': matchedPtsScores[jj]\n",
    "            })\n",
    "            # @TODO: Store match confidence!\n",
    "\n",
    "        #=== Track previous matches at current epoch ===#\n",
    "        if cfg.proc.do_tracking and epoch > 0:\n",
    "            print(f'Track points from epoch {epoch-1} to epoch {epoch}')\n",
    "\n",
    "            trackoutdir = epochdir / f'from_t{epoch-1}'\n",
    "            opt_tracking['output_dir'] = trackoutdir\n",
    "            pairs = [\n",
    "                [images[cams[0]].get_image_path(epoch-1),\n",
    "                    images[cams[0]].get_image_path(epoch)],\n",
    "                [images[cams[1]].get_image_path(epoch-1),\n",
    "                    images[cams[1]].get_image_path(epoch)],\n",
    "            ]\n",
    "            prevs = [\n",
    "                features[cams[0]][epoch-1].get_features_as_dict(),\n",
    "                features[cams[1]][epoch-1].get_features_as_dict()\n",
    "            ]\n",
    "            # Call actual tracking function\n",
    "            tracked_cam0, tracked_cam1 = track_matches(\n",
    "                pairs, cfg.images.bbox, prevs, opt_tracking)\n",
    "            # @TODO: keep track of the epoch in which feature is matched\n",
    "            # @TODO: Check bounding box in tracking\n",
    "            # @TODO: clean tracking code\n",
    "\n",
    "            # Store all matches in features structure\n",
    "            features[cams[0]][epoch].append_features(tracked_cam0)\n",
    "            features[cams[1]][epoch].append_features(tracked_cam1)\n",
    "\n",
    "        # Run Pydegensac to estimate F matrix and reject outliers\n",
    "        F, inlMask = pydegensac.findFundamentalMatrix(\n",
    "            features[cams[0]][epoch].get_keypoints(),\n",
    "            features[cams[1]][epoch].get_keypoints(),\n",
    "            px_th=1.5, conf=0.99999, max_iters=10000,\n",
    "            laf_consistensy_coef=-1.0,\n",
    "            error_type='sampson',\n",
    "            symmetric_error_check=True,\n",
    "            enable_degeneracy_check=True,\n",
    "        )\n",
    "        print(f'Matching at epoch {epoch}: pydegensac found {inlMask.sum()} \\\n",
    "            inliers ({inlMask.sum()*100/len(features[cams[0]][epoch]):.2f}%)')\n",
    "        features[cams[0]][epoch].remove_outliers_features(inlMask)\n",
    "        features[cams[1]][epoch].remove_outliers_features(inlMask)\n",
    "\n",
    "        # Write matched points to disk\n",
    "        im_stems = images[cams[0]].get_image_stem(\n",
    "            epoch), images[cams[1]].get_image_stem(epoch)\n",
    "        for jj, cam in enumerate(cams):\n",
    "            features[cam][epoch].save_as_txt(\n",
    "                epochdir / f'{im_stems[jj]}_mktps.txt')\n",
    "        with open(epochdir / f'{im_stems[0]}_{im_stems[1]}_features.pickle', 'wb') as f:\n",
    "            pickle.dump(features, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        last_match_path = create_directory('res/last_epoch')\n",
    "        with open(last_match_path / 'last_features.pickle', 'wb') as f:\n",
    "            pickle.dump(features, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        print('Matching completed')\n",
    "\n",
    "elif not features[cams[0]]:\n",
    "    last_match_path = 'res/last_epoch/last_features.pickle'\n",
    "    with open(last_match_path, 'rb') as f:\n",
    "        features = pickle.load(f)\n",
    "        print(\"Loaded previous matches\")\n",
    "else:\n",
    "    print(\"Features already present, nothing was changed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstructing epoch 0...\n",
      "Using OPENCV camera model.\n",
      "Using OPENCV camera model.\n",
      "Space resection succeded. Number of inlier points: 12/14\n",
      "Relative Orientation - valid points: 3540/3982\n",
      "Point triangulation succeded: 1.0.\n",
      "Loaded image IMG_1289.jpg\n",
      "Points color interpolated\n",
      "Point cloud filtered by Statistical Oulier Removal\n",
      "Reconstructing epoch 1...\n",
      "Using OPENCV camera model.\n",
      "Using OPENCV camera model.\n",
      "Space resection succeded. Number of inlier points: 12/14\n",
      "Relative Orientation - valid points: 4459/4799\n",
      "Point triangulation succeded: 1.0.\n",
      "Loaded image IMG_1290.jpg\n",
      "Points color interpolated\n",
      "Point cloud filtered by Statistical Oulier Removal\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "''' SfM '''\n",
    "\n",
    "# Initialize variables @TODO: build function for variable inizialization\n",
    "cameras = dict.fromkeys(cams)\n",
    "cameras[cams[0]], cameras[cams[1]] = [], []\n",
    "pcd = []\n",
    "tform = []\n",
    "# @TODO: store this information in exif inside an Image Class\n",
    "im_height, im_width = 4000, 6000\n",
    "\n",
    "\n",
    "# Read target image coordinates and object coordinates \n",
    "# @TODO: include onbject coordinate reading in methods\n",
    "# @TODO: rewrite methods for reading and storing targets information based on pandas\n",
    "targets = [Targets(cam_id=[0, 1],  im_coord_path=cfg.georef.target_paths),]\n",
    "targets[0].obj_coor = np.loadtxt(\"data/target_world.csv\",\n",
    "                              delimiter=\",\")\n",
    "\n",
    "# Camera baseline\n",
    "baseline_world = np.linalg.norm(\n",
    "    cfg.georef.camera_centers_world[0] - cfg.georef.camera_centers_world[1]\n",
    "    )\n",
    "\n",
    "for epoch in cfg.proc.epoch_to_process:\n",
    "    # epoch = 0\n",
    "    print(f'Reconstructing epoch {epoch}...')\n",
    "\n",
    "    # Initialize Intrinsics\n",
    "    ''' Inizialize Camera Intrinsics at every epoch setting them equal to\n",
    "        the reference cameras ones.\n",
    "    '''\n",
    "    # @TODO: replace append with insert or a more robust data structure...\n",
    "    for cam in cams:\n",
    "        cameras[cam].append(\n",
    "            Camera(\n",
    "                width=im_width,\n",
    "                height=im_height,\n",
    "                calib_path=cfg.paths.caldir / f'{cam}.txt'\n",
    "            )\n",
    "        )\n",
    "            \n",
    "    #--- Perform Space resection of the first camera by using GCPs ---#\n",
    "    ''' Initialize Single_camera_geometry class with a cameras object'''\n",
    "    # Temporary block to copy targets infos for every epoch\n",
    "    if len(targets) == 1:\n",
    "        targets.append(targets[0])\n",
    "    \n",
    "    space_resection = Single_camera_geometry(cameras[cams[0]][epoch])\n",
    "    space_resection.space_resection(\n",
    "        targets[epoch].get_im_coord(cam_id=0),\n",
    "        targets[epoch].get_obj_coord()\n",
    "        )\n",
    "    # Store result in camera 0 object\n",
    "    cameras[cams[0]][epoch] = space_resection.camera\n",
    "    \n",
    "    #--- Perform Relative orientation of the two cameras ---#\n",
    "    ''' Initialize Two_view_geometry class with a list containing the two cameras and a list contaning the matched features location on each camera.\n",
    "    '''\n",
    "    relative_ori = Two_view_geometry(\n",
    "        [cameras[cams[0]][epoch], cameras[cams[1]][epoch]],\n",
    "        [features[cams[0]][epoch].get_keypoints(),\n",
    "         features[cams[1]][epoch].get_keypoints()],\n",
    "    )\n",
    "    relative_ori.relative_orientation(\n",
    "        threshold=1.5, \n",
    "        confidence=0.999999, \n",
    "        scale_factor=261.60624502293524,\n",
    "        )\n",
    "    # Store result in camera 1 object\n",
    "    cameras[cams[1]][epoch] = relative_ori.cameras[1]\n",
    "    \n",
    "    # cam_baseline = np.linalg.norm(\n",
    "    #     cameras[cams[0]][0].get_C_from_pose() -\n",
    "    #     cameras[cams[1]][0].get_C_from_pose()\n",
    "    # )\n",
    "    # scale_fct = baseline_world / cam_baseline\n",
    "    # scale_fct = 261.60624502293524\n",
    "    \n",
    "    # Fix the EO of both the cameras as those estimated in the first epoch\n",
    "    # if epoch > 0:\n",
    "    #     for cam in cams:\n",
    "    #         cameras[cam][epoch] = cameras[cam][0]\n",
    "    #     print('Camera exterior orientation fixed to that of the master cameras.')\n",
    "\n",
    "    #--- Triangulate Points ---#\n",
    "    ''' Initialize Triangulate class with a list containing the two cameras\n",
    "        and a list contaning the matched features location on each camera.\n",
    "        Triangulated points are saved as points3d proprierty of the\n",
    "        Triangulate object (eg., triangulation.points3d)\n",
    "    '''\n",
    "    triangulation = Triangulate(\n",
    "        [cameras[cams[0]][epoch], \n",
    "         cameras[cams[1]][epoch]],\n",
    "        [features[cams[0]][epoch].get_keypoints(),\n",
    "         features[cams[1]][epoch].get_keypoints()]\n",
    "    )\n",
    "    triangulation.triangulate_two_views()\n",
    "    triangulation.interpolate_colors_from_image(\n",
    "        images[cams[1]][epoch],\n",
    "        cameras[cams[1]][epoch],\n",
    "        convert_BRG2RGB=True,\n",
    "    )\n",
    "\n",
    "  \n",
    "    # Create point cloud and save .ply to disk\n",
    "    pcd_epc = create_point_cloud(\n",
    "        triangulation.points3d, triangulation.colors)\n",
    "\n",
    "    # Filter outliers in point cloud with SOR filter\n",
    "    if cfg.other.do_SOR_filter:\n",
    "        _, ind = pcd_epc.remove_statistical_outlier(nb_neighbors=10,\n",
    "                                                    std_ratio=3.0)\n",
    "        #     display_pc_inliers(pcd_epc, ind)\n",
    "        pcd_epc = pcd_epc.select_by_index(ind)\n",
    "        print(\"Point cloud filtered by Statistical Oulier Removal\")\n",
    "\n",
    "    # Write point cloud to disk and store it in Point Cloud List\n",
    "    write_ply(pcd_epc, f'res/pt_clouds/sparse_pts_t{epoch}.ply')\n",
    "    pcd.append(pcd_epc)\n",
    "\n",
    "print('Done.')\n",
    "\n",
    "\n",
    "# Visualize point cloud\n",
    "display_point_cloud(\n",
    "    pcd,\n",
    "    [cameras[cams[0]][epoch], cameras[cams[1]][epoch]],\n",
    "    plot_scale=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded image IMG_2814.jpg\n",
      "Marker exported successfully\n",
      "Points exported successfully\n"
     ]
    }
   ],
   "source": [
    "from lib.io import export_keypoints_for_calge, export_points3D_for_calge\n",
    "\n",
    "epoch = 0\n",
    "export_keypoints_for_calge('simulaCalge/keypoints_280722.txt',\n",
    "                           features=features,\n",
    "                           imageds=images,\n",
    "                           epoch=epoch,\n",
    "                           pixel_size_micron=3.773\n",
    "                           )\n",
    "export_points3D_for_calge('simulaCalge/points3D_280722.txt',\n",
    "                           points3D=np.asarray(pcd[epoch].points)\n",
    "                           )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('belpy_gdal')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5257680a82f661cea8699dc8fe4567e52d11c753044270df4ff2b694c33cdedf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
