{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "Input parameters are valid.\n",
      "\n",
      "Image datastores created successfully.\n",
      "Processing epoch 0...\n",
      "Run Superglue to find matches at epoch 0\n",
      "Will not resize images\n",
      "Running inference on device \"cuda\"\n",
      "Loaded SuperPoint model\n",
      "Loaded SuperGlue model (\"outdoor\" weights)\n",
      "Will write matches to directory \"res/epoch_0\"\n",
      "Will write visualization images to directory \"res/epoch_0\"\n",
      "Warning: input resolution is very large, results may vary\n",
      "Warning: input resolution is very large, results may vary\n",
      "Images subdivided in 2x4 tiles\n",
      "[Finished Tile Pairs  0 -  0 of  8] matcher=6.028 viz_match=0.271 total=6.299 sec {0.2 FPS} \n",
      "[Finished Tile Pairs  1 -  1 of  8] matcher=5.631 viz_match=0.264 total=5.895 sec {0.2 FPS} \n",
      "[Finished Tile Pairs  2 -  2 of  8] matcher=5.068 viz_match=0.270 total=5.338 sec {0.2 FPS} \n",
      "[Finished Tile Pairs  3 -  3 of  8] matcher=4.936 viz_match=0.270 total=5.206 sec {0.2 FPS} \n",
      "[Finished Tile Pairs  4 -  4 of  8] matcher=4.432 viz_match=0.274 total=4.707 sec {0.2 FPS} \n",
      "[Finished Tile Pairs  5 -  5 of  8] matcher=4.512 viz_match=0.276 total=4.788 sec {0.2 FPS} \n",
      "[Finished Tile Pairs  6 -  6 of  8] matcher=4.523 viz_match=0.284 total=4.807 sec {0.2 FPS} \n",
      "[Finished Tile Pairs  7 -  7 of  8] matcher=4.558 viz_match=0.271 total=4.829 sec {0.2 FPS} \n",
      "[Finished pair] load_image=0.310 create_tiles=0.010 viz_match=39.715 total=40.035 sec {0.0 FPS} \n",
      "Matching at epoch 0: pydegensac found 4116             inliers (51.21%)\n",
      "Matching completed\n",
      "Processing epoch 1...\n",
      "Run Superglue to find matches at epoch 1\n",
      "Will not resize images\n",
      "Running inference on device \"cuda\"\n",
      "Loaded SuperPoint model\n",
      "Loaded SuperGlue model (\"outdoor\" weights)\n",
      "Will write matches to directory \"res/epoch_1\"\n",
      "Will write visualization images to directory \"res/epoch_1\"\n",
      "Warning: input resolution is very large, results may vary\n",
      "Warning: input resolution is very large, results may vary\n",
      "Images subdivided in 2x4 tiles\n",
      "[Finished Tile Pairs  0 -  0 of  8] matcher=4.543 viz_match=0.256 total=4.799 sec {0.2 FPS} \n",
      "[Finished Tile Pairs  1 -  1 of  8] matcher=4.551 viz_match=0.254 total=4.806 sec {0.2 FPS} \n",
      "[Finished Tile Pairs  2 -  2 of  8] matcher=4.344 viz_match=0.258 total=4.602 sec {0.2 FPS} \n",
      "[Finished Tile Pairs  3 -  3 of  8] matcher=4.422 viz_match=0.258 total=4.680 sec {0.2 FPS} \n",
      "[Finished Tile Pairs  4 -  4 of  8] matcher=4.232 viz_match=0.263 total=4.495 sec {0.2 FPS} \n",
      "[Finished Tile Pairs  5 -  5 of  8] matcher=4.375 viz_match=0.265 total=4.640 sec {0.2 FPS} \n",
      "[Finished Tile Pairs  6 -  6 of  8] matcher=4.492 viz_match=0.272 total=4.764 sec {0.2 FPS} \n",
      "[Finished Tile Pairs  7 -  7 of  8] matcher=4.546 viz_match=0.264 total=4.810 sec {0.2 FPS} \n",
      "[Finished pair] load_image=0.313 create_tiles=0.013 viz_match=38.834 total=39.161 sec {0.0 FPS} \n",
      "Track points from epoch 0 to epoch 1\n",
      "Will not resize images\n",
      "Running inference on device \"cuda\"\n",
      "Loaded SuperPoint model\n",
      "Loaded SuperGlue model (\"outdoor\" weights)\n",
      "Will write matches to directory \"res/epoch_1/from_t0\"\n",
      "Will write visualization images to directory \"res/epoch_1/from_t0\"\n",
      "Warning: input resolution is very large, results may vary\n",
      "Warning: input resolution is very large, results may vary\n",
      "Images subdivided in 2x4 tiles\n",
      "[Finished Tile Pairs  0 of  8] matcher=0.154 total=0.154 sec {6.5 FPS} \n",
      "[Finished Tile Pairs  1 of  8] matcher=0.148 total=0.148 sec {6.8 FPS} \n",
      "[Finished Tile Pairs  2 of  8] matcher=0.152 total=0.152 sec {6.6 FPS} \n",
      "[Finished Tile Pairs  3 of  8] matcher=0.159 total=0.159 sec {6.3 FPS} \n",
      "[Finished Tile Pairs  4 of  8] matcher=0.148 total=0.148 sec {6.8 FPS} \n",
      "[Finished Tile Pairs  5 of  8] matcher=0.145 total=0.145 sec {6.9 FPS} \n",
      "[Finished Tile Pairs  6 of  8] matcher=0.139 total=0.139 sec {7.2 FPS} \n",
      "[Finished Tile Pairs  7 of  8] matcher=0.129 total=0.129 sec {7.8 FPS} \n",
      "[Finished pair     1 of     2] load_image=0.304 create_tiles=0.013 viz_match=1.798 total=2.115 sec {0.5 FPS} \n",
      "Warning: input resolution is very large, results may vary\n",
      "Warning: input resolution is very large, results may vary\n",
      "Images subdivided in 2x4 tiles\n",
      "[Finished Tile Pairs  0 of  8] matcher=0.141 total=0.141 sec {7.1 FPS} \n",
      "[Finished Tile Pairs  1 of  8] matcher=0.134 total=0.134 sec {7.5 FPS} \n",
      "[Finished Tile Pairs  2 of  8] matcher=0.144 total=0.144 sec {6.9 FPS} \n",
      "[Finished Tile Pairs  3 of  8] matcher=0.151 total=0.151 sec {6.6 FPS} \n",
      "[Finished Tile Pairs  4 of  8] matcher=0.141 total=0.141 sec {7.1 FPS} \n",
      "[Finished Tile Pairs  5 of  8] matcher=0.147 total=0.147 sec {6.8 FPS} \n",
      "[Finished Tile Pairs  6 of  8] matcher=0.144 total=0.144 sec {6.9 FPS} \n",
      "[Finished Tile Pairs  7 of  8] matcher=0.135 total=0.135 sec {7.4 FPS} \n",
      "[Finished pair     2 of     2] load_image=0.312 create_tiles=0.014 viz_match=1.809 total=2.135 sec {0.5 FPS} \n",
      "Warning: input resolution is very large, results may vary\n",
      "Warning: input resolution is very large, results may vary\n",
      "Matching at epoch 1: pydegensac found 4118             inliers (54.94%)\n",
      "Matching completed\n",
      "Processing epoch 2...\n",
      "Run Superglue to find matches at epoch 2\n",
      "Will not resize images\n",
      "Running inference on device \"cuda\"\n",
      "Loaded SuperPoint model\n",
      "Loaded SuperGlue model (\"outdoor\" weights)\n",
      "Will write matches to directory \"res/epoch_2\"\n",
      "Will write visualization images to directory \"res/epoch_2\"\n",
      "Warning: input resolution is very large, results may vary\n",
      "Warning: input resolution is very large, results may vary\n",
      "Images subdivided in 2x4 tiles\n",
      "[Finished Tile Pairs  0 -  0 of  8] matcher=4.647 viz_match=0.269 total=4.916 sec {0.2 FPS} \n",
      "[Finished Tile Pairs  1 -  1 of  8] matcher=4.656 viz_match=0.261 total=4.916 sec {0.2 FPS} \n",
      "[Finished Tile Pairs  2 -  2 of  8] matcher=4.419 viz_match=0.263 total=4.682 sec {0.2 FPS} \n",
      "[Finished Tile Pairs  3 -  3 of  8] matcher=4.492 viz_match=0.264 total=4.755 sec {0.2 FPS} \n",
      "[Finished Tile Pairs  4 -  4 of  8] matcher=4.224 viz_match=0.265 total=4.489 sec {0.2 FPS} \n",
      "[Finished Tile Pairs  5 -  5 of  8] matcher=4.359 viz_match=0.262 total=4.621 sec {0.2 FPS} \n",
      "[Finished Tile Pairs  6 -  6 of  8] matcher=4.464 viz_match=0.270 total=4.733 sec {0.2 FPS} \n",
      "[Finished Tile Pairs  7 -  7 of  8] matcher=4.531 viz_match=0.260 total=4.791 sec {0.2 FPS} \n",
      "[Finished pair] load_image=0.313 create_tiles=0.011 viz_match=38.819 total=39.142 sec {0.0 FPS} \n",
      "Track points from epoch 1 to epoch 2\n",
      "Will not resize images\n",
      "Running inference on device \"cuda\"\n",
      "Loaded SuperPoint model\n",
      "Loaded SuperGlue model (\"outdoor\" weights)\n",
      "Will write matches to directory \"res/epoch_2/from_t1\"\n",
      "Will write visualization images to directory \"res/epoch_2/from_t1\"\n",
      "Warning: input resolution is very large, results may vary\n",
      "Warning: input resolution is very large, results may vary\n",
      "Images subdivided in 2x4 tiles\n",
      "[Finished Tile Pairs  0 of  8] matcher=0.148 total=0.148 sec {6.8 FPS} \n",
      "[Finished Tile Pairs  1 of  8] matcher=0.143 total=0.143 sec {7.0 FPS} \n",
      "[Finished Tile Pairs  2 of  8] matcher=0.147 total=0.147 sec {6.8 FPS} \n",
      "[Finished Tile Pairs  3 of  8] matcher=0.156 total=0.156 sec {6.4 FPS} \n",
      "[Finished Tile Pairs  4 of  8] matcher=0.147 total=0.147 sec {6.8 FPS} \n",
      "[Finished Tile Pairs  5 of  8] matcher=0.144 total=0.144 sec {6.9 FPS} \n",
      "[Finished Tile Pairs  6 of  8] matcher=0.139 total=0.139 sec {7.2 FPS} \n",
      "[Finished Tile Pairs  7 of  8] matcher=0.129 total=0.129 sec {7.7 FPS} \n",
      "[Finished pair     1 of     2] load_image=0.306 create_tiles=0.010 viz_match=1.808 total=2.124 sec {0.5 FPS} \n",
      "Warning: input resolution is very large, results may vary\n",
      "Warning: input resolution is very large, results may vary\n",
      "Images subdivided in 2x4 tiles\n",
      "[Finished Tile Pairs  0 of  8] matcher=0.140 total=0.140 sec {7.1 FPS} \n",
      "[Finished Tile Pairs  1 of  8] matcher=0.132 total=0.132 sec {7.5 FPS} \n",
      "[Finished Tile Pairs  2 of  8] matcher=0.143 total=0.143 sec {7.0 FPS} \n",
      "[Finished Tile Pairs  3 of  8] matcher=0.150 total=0.150 sec {6.7 FPS} \n",
      "[Finished Tile Pairs  4 of  8] matcher=0.140 total=0.140 sec {7.1 FPS} \n",
      "[Finished Tile Pairs  5 of  8] matcher=0.146 total=0.146 sec {6.8 FPS} \n",
      "[Finished Tile Pairs  6 of  8] matcher=0.144 total=0.144 sec {7.0 FPS} \n",
      "[Finished Tile Pairs  7 of  8] matcher=0.135 total=0.135 sec {7.4 FPS} \n",
      "[Finished pair     2 of     2] load_image=0.316 create_tiles=0.012 viz_match=1.818 total=2.145 sec {0.5 FPS} \n",
      "Warning: input resolution is very large, results may vary\n",
      "Warning: input resolution is very large, results may vary\n",
      "Matching at epoch 2: pydegensac found 3964             inliers (52.38%)\n",
      "Matching completed\n",
      "Processing epoch 3...\n",
      "Run Superglue to find matches at epoch 3\n",
      "Will not resize images\n",
      "Running inference on device \"cuda\"\n",
      "Loaded SuperPoint model\n",
      "Loaded SuperGlue model (\"outdoor\" weights)\n",
      "Will write matches to directory \"res/epoch_3\"\n",
      "Will write visualization images to directory \"res/epoch_3\"\n",
      "Warning: input resolution is very large, results may vary\n",
      "Warning: input resolution is very large, results may vary\n",
      "Images subdivided in 2x4 tiles\n",
      "[Finished Tile Pairs  0 -  0 of  8] matcher=4.654 viz_match=0.259 total=4.912 sec {0.2 FPS} \n",
      "[Finished Tile Pairs  1 -  1 of  8] matcher=4.680 viz_match=0.253 total=4.933 sec {0.2 FPS} \n",
      "[Finished Tile Pairs  2 -  2 of  8] matcher=4.316 viz_match=0.259 total=4.575 sec {0.2 FPS} \n",
      "[Finished Tile Pairs  3 -  3 of  8] matcher=4.428 viz_match=0.262 total=4.690 sec {0.2 FPS} \n",
      "[Finished Tile Pairs  4 -  4 of  8] matcher=3.934 viz_match=0.262 total=4.196 sec {0.2 FPS} \n",
      "[Finished Tile Pairs  5 -  5 of  8] matcher=4.167 viz_match=0.264 total=4.432 sec {0.2 FPS} \n",
      "[Finished Tile Pairs  6 -  6 of  8] matcher=4.240 viz_match=0.264 total=4.504 sec {0.2 FPS} \n",
      "[Finished Tile Pairs  7 -  7 of  8] matcher=4.362 viz_match=0.255 total=4.617 sec {0.2 FPS} \n",
      "[Finished pair] load_image=0.299 create_tiles=0.010 viz_match=37.351 total=37.660 sec {0.0 FPS} \n",
      "Track points from epoch 2 to epoch 3\n",
      "Will not resize images\n",
      "Running inference on device \"cuda\"\n",
      "Loaded SuperPoint model\n",
      "Loaded SuperGlue model (\"outdoor\" weights)\n",
      "Will write matches to directory \"res/epoch_3/from_t2\"\n",
      "Will write visualization images to directory \"res/epoch_3/from_t2\"\n",
      "Warning: input resolution is very large, results may vary\n",
      "Warning: input resolution is very large, results may vary\n",
      "Images subdivided in 2x4 tiles\n",
      "[Finished Tile Pairs  0 of  8] matcher=0.148 total=0.148 sec {6.7 FPS} \n",
      "[Finished Tile Pairs  1 of  8] matcher=0.142 total=0.142 sec {7.0 FPS} \n",
      "[Finished Tile Pairs  2 of  8] matcher=0.147 total=0.147 sec {6.8 FPS} \n",
      "[Finished Tile Pairs  3 of  8] matcher=0.156 total=0.156 sec {6.4 FPS} \n",
      "[Finished Tile Pairs  4 of  8] matcher=0.144 total=0.144 sec {6.9 FPS} \n",
      "[Finished Tile Pairs  5 of  8] matcher=0.142 total=0.142 sec {7.0 FPS} \n",
      "[Finished Tile Pairs  6 of  8] matcher=0.133 total=0.133 sec {7.5 FPS} \n",
      "[Finished Tile Pairs  7 of  8] matcher=0.127 total=0.127 sec {7.9 FPS} \n",
      "[Finished pair     1 of     2] load_image=0.298 create_tiles=0.007 viz_match=1.758 total=2.063 sec {0.5 FPS} \n",
      "Warning: input resolution is very large, results may vary\n",
      "Warning: input resolution is very large, results may vary\n",
      "Images subdivided in 2x4 tiles\n",
      "[Finished Tile Pairs  0 of  8] matcher=0.137 total=0.137 sec {7.3 FPS} \n",
      "[Finished Tile Pairs  1 of  8] matcher=0.130 total=0.130 sec {7.7 FPS} \n",
      "[Finished Tile Pairs  2 of  8] matcher=0.139 total=0.139 sec {7.2 FPS} \n",
      "[Finished Tile Pairs  3 of  8] matcher=0.147 total=0.147 sec {6.8 FPS} \n",
      "[Finished Tile Pairs  4 of  8] matcher=0.134 total=0.134 sec {7.4 FPS} \n",
      "[Finished Tile Pairs  5 of  8] matcher=0.143 total=0.143 sec {7.0 FPS} \n",
      "[Finished Tile Pairs  6 of  8] matcher=0.137 total=0.137 sec {7.3 FPS} \n",
      "[Finished Tile Pairs  7 of  8] matcher=0.129 total=0.129 sec {7.7 FPS} \n",
      "[Finished pair     2 of     2] load_image=0.307 create_tiles=0.009 viz_match=1.767 total=2.082 sec {0.5 FPS} \n",
      "Warning: input resolution is very large, results may vary\n",
      "Warning: input resolution is very large, results may vary\n",
      "Matching at epoch 3: pydegensac found 3683             inliers (49.40%)\n",
      "Matching completed\n",
      "Processing epoch 4...\n",
      "Run Superglue to find matches at epoch 4\n",
      "Will not resize images\n",
      "Running inference on device \"cuda\"\n",
      "Loaded SuperPoint model\n",
      "Loaded SuperGlue model (\"outdoor\" weights)\n",
      "Will write matches to directory \"res/epoch_4\"\n",
      "Will write visualization images to directory \"res/epoch_4\"\n",
      "Warning: input resolution is very large, results may vary\n",
      "Warning: input resolution is very large, results may vary\n",
      "Images subdivided in 2x4 tiles\n",
      "[Finished Tile Pairs  0 -  0 of  8] matcher=4.064 viz_match=0.253 total=4.317 sec {0.2 FPS} \n",
      "[Finished Tile Pairs  1 -  1 of  8] matcher=4.263 viz_match=0.251 total=4.514 sec {0.2 FPS} \n",
      "[Finished Tile Pairs  2 -  2 of  8] matcher=3.853 viz_match=0.252 total=4.105 sec {0.2 FPS} \n",
      "[Finished Tile Pairs  3 -  3 of  8] matcher=4.103 viz_match=0.259 total=4.361 sec {0.2 FPS} \n",
      "[Finished Tile Pairs  4 -  4 of  8] matcher=3.549 viz_match=0.255 total=3.804 sec {0.3 FPS} \n",
      "[Finished Tile Pairs  5 -  5 of  8] matcher=3.831 viz_match=0.260 total=4.091 sec {0.2 FPS} \n",
      "[Finished Tile Pairs  6 -  6 of  8] matcher=3.863 viz_match=0.259 total=4.122 sec {0.2 FPS} \n",
      "[Finished Tile Pairs  7 -  7 of  8] matcher=4.100 viz_match=0.252 total=4.352 sec {0.2 FPS} \n",
      "[Finished pair] load_image=0.280 create_tiles=0.011 viz_match=34.965 total=35.255 sec {0.0 FPS} \n",
      "Track points from epoch 3 to epoch 4\n",
      "Will not resize images\n",
      "Running inference on device \"cuda\"\n",
      "Loaded SuperPoint model\n",
      "Loaded SuperGlue model (\"outdoor\" weights)\n",
      "Will write matches to directory \"res/epoch_4/from_t3\"\n",
      "Will write visualization images to directory \"res/epoch_4/from_t3\"\n",
      "Warning: input resolution is very large, results may vary\n",
      "Warning: input resolution is very large, results may vary\n",
      "Images subdivided in 2x4 tiles\n",
      "[Finished Tile Pairs  0 of  8] matcher=0.143 total=0.143 sec {7.0 FPS} \n",
      "[Finished Tile Pairs  1 of  8] matcher=0.138 total=0.138 sec {7.3 FPS} \n",
      "[Finished Tile Pairs  2 of  8] matcher=0.142 total=0.142 sec {7.0 FPS} \n",
      "[Finished Tile Pairs  3 of  8] matcher=0.152 total=0.152 sec {6.6 FPS} \n",
      "[Finished Tile Pairs  4 of  8] matcher=0.140 total=0.140 sec {7.2 FPS} \n",
      "[Finished Tile Pairs  5 of  8] matcher=0.139 total=0.139 sec {7.2 FPS} \n",
      "[Finished Tile Pairs  6 of  8] matcher=0.126 total=0.126 sec {7.9 FPS} \n",
      "[Finished Tile Pairs  7 of  8] matcher=0.121 total=0.121 sec {8.3 FPS} \n",
      "[Finished pair     1 of     2] load_image=0.285 create_tiles=0.010 viz_match=1.705 total=2.000 sec {0.5 FPS} \n",
      "Warning: input resolution is very large, results may vary\n",
      "Warning: input resolution is very large, results may vary\n",
      "Images subdivided in 2x4 tiles\n",
      "[Finished Tile Pairs  0 of  8] matcher=0.137 total=0.137 sec {7.3 FPS} \n",
      "[Finished Tile Pairs  1 of  8] matcher=0.130 total=0.130 sec {7.7 FPS} \n",
      "[Finished Tile Pairs  2 of  8] matcher=0.138 total=0.138 sec {7.3 FPS} \n",
      "[Finished Tile Pairs  3 of  8] matcher=0.145 total=0.145 sec {6.9 FPS} \n",
      "[Finished Tile Pairs  4 of  8] matcher=0.132 total=0.132 sec {7.6 FPS} \n",
      "[Finished Tile Pairs  5 of  8] matcher=0.141 total=0.141 sec {7.1 FPS} \n",
      "[Finished Tile Pairs  6 of  8] matcher=0.128 total=0.128 sec {7.8 FPS} \n",
      "[Finished Tile Pairs  7 of  8] matcher=0.123 total=0.123 sec {8.1 FPS} \n",
      "[Finished pair     2 of     2] load_image=0.300 create_tiles=0.012 viz_match=1.711 total=2.023 sec {0.5 FPS} \n",
      "Warning: input resolution is very large, results may vary\n",
      "Warning: input resolution is very large, results may vary\n",
      "Matching at epoch 4: pydegensac found 4428             inliers (53.13%)\n",
      "Matching completed\n"
     ]
    }
   ],
   "source": [
    "from lib.validate_inputs import validate\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pickle\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import pydegensac\n",
    "\n",
    "from pathlib import Path\n",
    "from easydict import EasyDict as edict\n",
    "\n",
    "from lib.config import parse_yaml_cfg\n",
    "from lib.classes import (Camera, Imageds, Features, Targets)\n",
    "from lib.sfm.two_view_geometry import Two_view_geometry\n",
    "from lib.sfm.triangulation import Triangulate\n",
    "from lib.match_pairs import match_pair\n",
    "from lib.track_matches import track_matches\n",
    "\n",
    "from lib.geometry import (project_points,\n",
    "                          compute_reprojection_error\n",
    "                          )\n",
    "from lib.utils import (build_dsm,\n",
    "                       generate_ortophoto,\n",
    "                       )\n",
    "from lib.point_clouds import (create_point_cloud,\n",
    "                              write_ply,\n",
    "                              )\n",
    "from lib.visualization import (display_point_cloud,\n",
    "                               display_pc_inliers,\n",
    "                               plot_features,\n",
    "                               plot_projections,\n",
    "                               )\n",
    "from lib.misc import (convert_to_homogeneous,\n",
    "                      convert_from_homogeneous,\n",
    "                      create_directory,\n",
    "                      )\n",
    "\n",
    "from thirdparty.transformations import affine_matrix_from_points\n",
    "\n",
    "# Parse options from yaml file\n",
    "cfg_file = 'config/config_base.yaml'\n",
    "cfg = parse_yaml_cfg(cfg_file)\n",
    "\n",
    "# Inizialize Variables\n",
    "cams = cfg.paths.cam_names\n",
    "features = dict.fromkeys(cams)  # @TODO: put this in an inizialization function\n",
    "\n",
    "# Create Image Datastore objects\n",
    "images = dict.fromkeys(cams)  # @TODO: put this in an inizialization function\n",
    "for cam in cams:\n",
    "    images[cam] = Imageds(cfg.paths.imdir / cam)\n",
    "\n",
    "cfg = validate(cfg, images)\n",
    "\n",
    "''' Perform matching and tracking '''\n",
    "# Load matching and tracking configurations\n",
    "with open(cfg.matching_cfg) as f:\n",
    "    opt_matching = edict(json.load(f))\n",
    "with open(cfg.tracking_cfg) as f:\n",
    "    opt_tracking = edict(json.load(f))\n",
    "\n",
    "# epoch = 0\n",
    "if cfg.proc.do_matching:\n",
    "    for cam in cams:\n",
    "        features[cam] = []\n",
    "\n",
    "    for epoch in cfg.proc.epoch_to_process:\n",
    "        print(f'Processing epoch {epoch}...')\n",
    "\n",
    "        # opt_matching = cfg.matching.copy()\n",
    "        epochdir = Path(cfg.paths.resdir) / f'epoch_{epoch}'\n",
    "\n",
    "        #-- Find Matches at current epoch --#\n",
    "        print(f'Run Superglue to find matches at epoch {epoch}')\n",
    "        opt_matching.output_dir = epochdir\n",
    "        pair = [\n",
    "            images[cams[0]].get_image_path(epoch),\n",
    "            images[cams[1]].get_image_path(epoch)\n",
    "        ]\n",
    "        # Call matching function\n",
    "        matchedPts, matchedDescriptors, matchedPtsScores = match_pair(\n",
    "            pair, cfg.images.bbox, opt_matching\n",
    "        )\n",
    "\n",
    "        # Store matches in features structure\n",
    "        for jj, cam in enumerate(cams):\n",
    "            # Dict keys are the cameras names, internal list contain epoches\n",
    "            features[cam].append(Features())\n",
    "            features[cam][epoch].append_features({\n",
    "                'kpts': matchedPts[jj],\n",
    "                'descr': matchedDescriptors[jj],\n",
    "                'score': matchedPtsScores[jj]\n",
    "            })\n",
    "            # @TODO: Store match confidence!\n",
    "\n",
    "        #=== Track previous matches at current epoch ===#\n",
    "        if cfg.proc.do_tracking and epoch > 0:\n",
    "            print(f'Track points from epoch {epoch-1} to epoch {epoch}')\n",
    "\n",
    "            trackoutdir = epochdir / f'from_t{epoch-1}'\n",
    "            opt_tracking['output_dir'] = trackoutdir\n",
    "            pairs = [\n",
    "                [images[cams[0]].get_image_path(epoch-1),\n",
    "                    images[cams[0]].get_image_path(epoch)],\n",
    "                [images[cams[1]].get_image_path(epoch-1),\n",
    "                    images[cams[1]].get_image_path(epoch)],\n",
    "            ]\n",
    "            prevs = [\n",
    "                features[cams[0]][epoch-1].get_features_as_dict(),\n",
    "                features[cams[1]][epoch-1].get_features_as_dict()\n",
    "            ]\n",
    "            # Call actual tracking function\n",
    "            tracked_cam0, tracked_cam1 = track_matches(\n",
    "                pairs, cfg.images.bbox, prevs, opt_tracking)\n",
    "            # @TODO: keep track of the epoch in which feature is matched\n",
    "            # @TODO: Check bounding box in tracking\n",
    "            # @TODO: clean tracking code\n",
    "\n",
    "            # Store all matches in features structure\n",
    "            features[cams[0]][epoch].append_features(tracked_cam0)\n",
    "            features[cams[1]][epoch].append_features(tracked_cam1)\n",
    "\n",
    "        # Run Pydegensac to estimate F matrix and reject outliers\n",
    "        F, inlMask = pydegensac.findFundamentalMatrix(\n",
    "            features[cams[0]][epoch].get_keypoints(),\n",
    "            features[cams[1]][epoch].get_keypoints(),\n",
    "            px_th=1.5, conf=0.99999, max_iters=10000,\n",
    "            laf_consistensy_coef=-1.0,\n",
    "            error_type='sampson',\n",
    "            symmetric_error_check=True,\n",
    "            enable_degeneracy_check=True,\n",
    "        )\n",
    "        print(f'Matching at epoch {epoch}: pydegensac found {inlMask.sum()} \\\n",
    "            inliers ({inlMask.sum()*100/len(features[cams[0]][epoch]):.2f}%)')\n",
    "        features[cams[0]][epoch].remove_outliers_features(inlMask)\n",
    "        features[cams[1]][epoch].remove_outliers_features(inlMask)\n",
    "\n",
    "        # Write matched points to disk\n",
    "        im_stems = images[cams[0]].get_image_stem(\n",
    "            epoch), images[cams[1]].get_image_stem(epoch)\n",
    "        for jj, cam in enumerate(cams):\n",
    "            features[cam][epoch].save_as_txt(\n",
    "                epochdir / f'{im_stems[jj]}_mktps.txt')\n",
    "        with open(epochdir / f'{im_stems[0]}_{im_stems[1]}_features.pickle', 'wb') as f:\n",
    "            pickle.dump(features, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        last_match_path = create_directory('res/last_epoch')\n",
    "        with open(last_match_path / 'last_features.pickle', 'wb') as f:\n",
    "            pickle.dump(features, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        print('Matching completed')\n",
    "\n",
    "elif not features[cams[0]]:\n",
    "    last_match_path = 'res/last_epoch/last_features.pickle'\n",
    "    with open(last_match_path, 'rb') as f:\n",
    "        features = pickle.load(f)\n",
    "        print(\"Loaded previous matches\")\n",
    "else:\n",
    "    print(\"Features already present, nothing was changed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using OPENCV camera model.\n",
      "Using OPENCV camera model.\n",
      "Reconstructing epoch 0...\n",
      "Relative Orientation - valid points: 3697/4116\n",
      "Point triangulation succeded: 1.0.\n",
      "Loaded image IMG_1282.jpg\n",
      "Points color interpolated\n",
      "Point cloud filtered by Statistical Oulier Removal\n",
      "Reconstructing epoch 1...\n",
      "Relative Orientation - valid points: 3821/4118\n",
      "Camera exterior orientation fixed to that of the master cameras.\n",
      "Point triangulation succeded: 1.0.\n",
      "Loaded image IMG_1284.jpg\n",
      "Points color interpolated\n",
      "Point cloud filtered by Statistical Oulier Removal\n",
      "Reconstructing epoch 2...\n",
      "Relative Orientation - valid points: 3355/3964\n",
      "Camera exterior orientation fixed to that of the master cameras.\n",
      "Point triangulation succeded: 1.0.\n",
      "Loaded image IMG_1286.jpg\n",
      "Points color interpolated\n",
      "Point cloud filtered by Statistical Oulier Removal\n",
      "Reconstructing epoch 3...\n",
      "Relative Orientation - valid points: 3225/3683\n",
      "Camera exterior orientation fixed to that of the master cameras.\n",
      "Point triangulation succeded: 1.0.\n",
      "Loaded image IMG_1289.jpg\n",
      "Points color interpolated\n",
      "Point cloud filtered by Statistical Oulier Removal\n",
      "Reconstructing epoch 4...\n",
      "Relative Orientation - valid points: 4139/4428\n",
      "Camera exterior orientation fixed to that of the master cameras.\n",
      "Point triangulation succeded: 1.0.\n",
      "Loaded image IMG_1290.jpg\n",
      "Points color interpolated\n",
      "Point cloud filtered by Statistical Oulier Removal\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "''' SfM '''\n",
    "\n",
    "# Initialize variables\n",
    "cameras = dict.fromkeys(cams)\n",
    "cameras[cams[0]], cameras[cams[1]] = [], []\n",
    "pcd = []\n",
    "tform = []\n",
    "h, w = 4000, 6000\n",
    "\n",
    "# Build reference camera objects with only known interior orientation\n",
    "ref_cams = dict.fromkeys(cams)\n",
    "for jj, cam in enumerate(cams):\n",
    "    ref_cams[cam] = Camera(\n",
    "        width=6000, height=400,\n",
    "        calib_path=cfg.paths.caldir / f'{cam}.txt'\n",
    "    )\n",
    "\n",
    "# Read target image coordinates\n",
    "targets = Targets(cam_id=[0, 1],  im_coord_path=cfg.georef.target_paths)\n",
    "\n",
    "# Camera baseline\n",
    "baseline_world = np.linalg.norm(\n",
    "    cfg.georef.camera_centers_world[0] - cfg.georef.camera_centers_world[1]\n",
    ")\n",
    "\n",
    "for epoch in cfg.proc.epoch_to_process:\n",
    "    # epoch = 0\n",
    "    print(f'Reconstructing epoch {epoch}...')\n",
    "\n",
    "    # Initialize Intrinsics\n",
    "    ''' Inizialize Camera Intrinsics at every epoch setting them equal to\n",
    "        the reference cameras ones.\n",
    "    '''\n",
    "    # @TODO: replace append with insert or a more robust data structure...\n",
    "    for cam in cams:\n",
    "        cameras[cam].append(\n",
    "            Camera(\n",
    "                width=ref_cams[cam].width,\n",
    "                height=ref_cams[cam].height,\n",
    "                K=ref_cams[cam].K,\n",
    "                dist=ref_cams[cam].dist,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Perform Relative orientation of the two cameras\n",
    "    ''' Initialize Two_view_geometry class with a list containing the two cameras\n",
    "        and a list contaning the matched features location on each camera.\n",
    "    '''\n",
    "    relative_ori = Two_view_geometry(\n",
    "        [cameras[cams[0]][epoch], cameras[cams[1]][epoch]],\n",
    "        [features[cams[0]][epoch].get_keypoints(),\n",
    "            features[cams[1]][epoch].get_keypoints()],\n",
    "    )\n",
    "    relative_ori.relative_orientation(threshold=1.5, confidence=0.999999)\n",
    "    relative_ori.scale_model_with_baseline(baseline_world)\n",
    "\n",
    "    # Save relative orientation results in Camera objects of current epoch\n",
    "    cameras[cams[0]][epoch] = relative_ori.cameras[0]\n",
    "    cameras[cams[1]][epoch] = relative_ori.cameras[1]\n",
    "\n",
    "    if cfg.proc.do_coregistration:\n",
    "        # @TODO: make wrappers to handle RS transformations\n",
    "\n",
    "        # Triangulate targets\n",
    "        triangulate = Triangulate(\n",
    "            [cameras[cams[0]][epoch], cameras[cams[1]][epoch]],\n",
    "            [targets.get_im_coord(0)[epoch],\n",
    "                targets.get_im_coord(1)[epoch]],\n",
    "        )\n",
    "        targets.append_obj_cord(triangulate.triangulate_two_views())\n",
    "\n",
    "        # Estimate rigid body transformation between first epoch RS and current epoch RS\n",
    "        # @TODO: make a wrapper for this\n",
    "        v0 = np.concatenate((cameras[cams[0]][0].C,\n",
    "                             cameras[cams[1]][0].C,\n",
    "                             targets.get_obj_coord()[0].reshape(3, 1),\n",
    "                             ), axis=1)\n",
    "        v1 = np.concatenate((cameras[cams[0]][epoch].C,\n",
    "                             cameras[cams[1]][epoch].C,\n",
    "                             targets.get_obj_coord()[epoch].reshape(3, 1),\n",
    "                             ), axis=1)\n",
    "        tform.append(affine_matrix_from_points(\n",
    "            v1, v0, shear=False, scale=False, usesvd=True))\n",
    "        print('Point cloud coregistered based on {len(v0)} points.')\n",
    "\n",
    "    elif epoch > 0:\n",
    "        # Fix the EO of both the cameras as those estimated in the first epoch\n",
    "        for cam in cams:\n",
    "            cameras[cam][epoch] = cameras[cam][0]\n",
    "        print('Camera exterior orientation fixed to that of the master cameras.')\n",
    "\n",
    "    #--- Triangulate Points ---#\n",
    "    ''' Initialize Triangulate class with a list containing the two cameras\n",
    "        and a list contaning the matched features location on each camera.\n",
    "        Triangulated points are saved as points3d proprierty of the\n",
    "        Triangulate object (eg., triangulation.points3d)\n",
    "    '''\n",
    "    triangulation = Triangulate(\n",
    "        [cameras[cams[0]][epoch], cameras[cams[1]][epoch]],\n",
    "        [\n",
    "            features[cams[0]][epoch].get_keypoints(),\n",
    "            features[cams[1]][epoch].get_keypoints()\n",
    "        ]\n",
    "    )\n",
    "    triangulation.triangulate_two_views()\n",
    "    triangulation.interpolate_colors_from_image(\n",
    "        images[cams[1]][epoch],\n",
    "        cameras[cams[1]][epoch],\n",
    "        convert_BRG2RGB=True,\n",
    "    )\n",
    "\n",
    "    if cfg.proc.do_coregistration:\n",
    "        # Apply rigid body transformation to triangulated points\n",
    "        # @TODO: make wrapper for apply transformation to arrays\n",
    "        pts = np.dot(tform[epoch],\n",
    "                     convert_to_homogeneous(triangulation.points3d.T)\n",
    "                     )\n",
    "        triangulation.points3d = convert_from_homogeneous(pts).T\n",
    "\n",
    "    # Create point cloud and save .ply to disk\n",
    "    pcd_epc = create_point_cloud(\n",
    "        triangulation.points3d, triangulation.colors)\n",
    "\n",
    "    # Filter outliers in point cloud with SOR filter\n",
    "    if cfg.other.do_SOR_filter:\n",
    "        _, ind = pcd_epc.remove_statistical_outlier(nb_neighbors=10,\n",
    "                                                    std_ratio=3.0)\n",
    "        #     display_pc_inliers(pcd_epc, ind)\n",
    "        pcd_epc = pcd_epc.select_by_index(ind)\n",
    "        print(\"Point cloud filtered by Statistical Oulier Removal\")\n",
    "\n",
    "    # Write point cloud to disk and store it in Point Cloud List\n",
    "    write_ply(pcd_epc, f'res/pt_clouds/sparse_pts_t{epoch}.ply')\n",
    "    pcd.append(pcd_epc)\n",
    "\n",
    "print('Done.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded image IMG_2814.jpg\n",
      "Marker exported successfully\n"
     ]
    }
   ],
   "source": [
    "'''Export image coordinates'''\n",
    "\n",
    "# from lib.io import export_keypoints_for_calge\n",
    "def export_keypoints_for_calge(\n",
    "    filename: str,\n",
    "    features: Features,\n",
    "    imageds: Imageds,\n",
    "    epoch: int = None,\n",
    "    pixel_size_micron: float = None,\n",
    ") -> None:\n",
    "    \"\"\" Write keypoints image coordinates to csv file,\n",
    "    sort by camera, as follows:\n",
    "    cam1, kpt1, x, y\n",
    "    cam1, kpt2, x, y\n",
    "    ...\n",
    "    cam1, kptM, x, y\n",
    "    cam2, kpt1, x, y\n",
    "    ....\n",
    "    camN, kptM, x, y\n",
    "\n",
    "    Args:\n",
    "        filename (str): path of the output csv file\n",
    "        features (calsses.Features):\n",
    "        imageds (calsses.Imageds):\n",
    "        epoch (int, default = None):\n",
    "        pixel_size_micron (float, default = None) [micron]\n",
    "    \"\"\"\n",
    "\n",
    "    if epoch is not None:\n",
    "\n",
    "        cams = list(imageds.keys())\n",
    "\n",
    "        # Write header to file\n",
    "        file = open(filename, \"w\")\n",
    "        if pixel_size_micron is not None:\n",
    "            file.write(\"image_name, feature_id, xi, eta\\n\")\n",
    "            img = imageds[cams[0]][epoch]\n",
    "            img_size = img.shape[:2]\n",
    "        else:\n",
    "            file.write(\"image_name, feature_id, x, y\\n\")\n",
    "\n",
    "        for cam in cams:\n",
    "            image_name = imageds[cam].get_image_name(epoch)\n",
    "\n",
    "            for id, kpt in enumerate(features[cam][epoch].get_keypoints()):\n",
    "                x, y = kpt\n",
    "\n",
    "                # If pixel_size_micron is not empty, convert image coordinates from x-y (row,column) image coordinate system to xi-eta image coordinate system (origin at the center of the image, xi towards right, eta upwards)\n",
    "                if pixel_size_micron is not None:\n",
    "                    xi = (x - img_size[1]/2) * pixel_size_micron\n",
    "                    eta = (img_size[0]/2 - y) * pixel_size_micron\n",
    "\n",
    "                    file.write(\n",
    "                        f\"{image_name},{id:05},{xi:8.1f},{eta:8.1f} \\n\")\n",
    "                else:\n",
    "                    file.write(\n",
    "                        f\"{image_name},{id:05},{x:.1f},{y:.1f} \\n\")\n",
    "\n",
    "        file.close()\n",
    "        print(\"Marker exported successfully\")\n",
    "    else:\n",
    "        print('please, provide the epoch number.')\n",
    "        return\n",
    "\n",
    "epoch = 3\n",
    "\n",
    "export_keypoints_for_calge('simulaCalge/keypoints_280722.txt',\n",
    "                           features=features,\n",
    "                           imageds=images,\n",
    "                           epoch=epoch, \n",
    "                           pixel_size_micron=3.773\n",
    "                           )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Points exported successfully\n"
     ]
    }
   ],
   "source": [
    "''' Export object coordinates'''\n",
    "\n",
    "\n",
    "def export_points3D_for_calge(\n",
    "    filename: str,\n",
    "    points3D: np.ndarray,\n",
    ") -> None:\n",
    "    \"\"\" Write 3D world coordinates of matched points to csv file,\n",
    "    sort by camera, as follows:\n",
    "    marker1, X, Y, Z\n",
    "    ...\n",
    "    markerM, X, Y, Z\n",
    "\n",
    "    Args:\n",
    "        filename (str): path of the output csv file\n",
    "        points3D (np.ndarray):\n",
    "    \"\"\"\n",
    "\n",
    "    # Write header to file\n",
    "    file = open(filename, \"w\")\n",
    "    file.write(\"point_id, X, Y, Z\\n\")\n",
    "    \n",
    "    for id, pt in enumerate(points3D):\n",
    "        file.write(f\"{id:05},{pt[0]:8.4f},{pt[1]:8.4f},{pt[2]:8.4f}\\n\")\n",
    "\n",
    "    file.close()\n",
    "    print(\"Points exported successfully\")\n",
    "\n",
    "\n",
    "epoch = 3\n",
    "export_points3D_for_calge('simulaCalge/points3D_280722.txt',\n",
    "                           points3D=np.asarray(pcd[epoch].points)\n",
    "                           )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "\n",
    "# from traceback import print_tb\n",
    "\n",
    "from lib.visualization import display_point_cloud\n",
    "from thirdparty.transformations import euler_from_matrix, euler_matrix\n",
    "\n",
    "cam1_loc = ref_cams[cams[0]]\n",
    "cam2_loc = ref_cams[cams[1]]\n",
    "\n",
    "# IMG_1289.jpg \n",
    "# loc = np.array([312.930747,300.536595,135.159918]).reshape(3,-1)\n",
    "# angles = np.deg2rad(np.array([-83.914310,80.177810,174.222339]))\n",
    "\n",
    "# IMG_2814.jpg\n",
    "loc = np.array([151.703845, 99.171778, 91.618363]).reshape(3, -1)\n",
    "ang = np.deg2rad(np.array([100.281584, 54.781799, -12.652574]))\n",
    "R1_world2cam = euler_matrix(ang[0], ang[1], ang[2])[:3,:3]\n",
    "# print(R_world2cam1_loc)\n",
    "\n",
    "# Read point cloud in LOC RS\n",
    "sparse_loc = o3d.io.read_point_cloud('belvedere_20220728_sparse_LOC.ply')\n",
    "\n",
    "# Define cam1_locera EO\n",
    "\n",
    "\n",
    "def build_pose_matrix(R: np.ndarray, C: np.ndarray) -> np.ndarray:\n",
    "    # Check for input dimensions \n",
    "    if R.shape != (3,3):\n",
    "        raise ValueError('Wrong dimension of the R matrix. It must be a 3x3 numpy array')\n",
    "    if C.shape == (3,) or C.shape == (1,3):\n",
    "        C = C.T\n",
    "    elif C.shape != (3,1):\n",
    "        raise ValueError('Wrong dimension of the C vector. It must be a 3x1 or a 1x3 numpy array')\n",
    "    \n",
    "    pose = np.eye(4)\n",
    "    pose[0:3, 0:3] = R\n",
    "    pose[0:3, 3:4] = C\n",
    "    return pose \n",
    "\n",
    "def compute_camera_EO(camera: Camera, \n",
    "                      extrinsics: np.ndarray = None, \n",
    "                      pose: np.ndarray = None\n",
    "                      ) -> Camera:\n",
    "    \n",
    "    if extrinsics is not None:\n",
    "        camera.extrinsics = extrinsics\n",
    "        camera.extrinsics_to_pose()\n",
    "        camera.update_camera_from_extrinsics()\n",
    "        return camera\n",
    "    \n",
    "    if pose is not None: \n",
    "        camera.pose = pose\n",
    "        camera.pose_to_extrinsics()\n",
    "        camera.update_camera_from_extrinsics()\n",
    "        return camera\n",
    "    \n",
    "    else: \n",
    "        raise ValueError('Not enough data to build Camera External Orientation matrixes.')\n",
    "\n",
    "\n",
    "cam1toWorld = build_pose_matrix(R1_world2cam.T, loc) @ cameras[cams[0]][0].pose\n",
    "cam1_loc = compute_camera_EO(cam1_loc, pose=cam1toWorld)\n",
    "\n",
    "cam2toWorld = cam1_loc.pose @ cameras[cams[1]][0].pose\n",
    "cam2_loc = compute_camera_EO(cam2_loc, pose=cam2toWorld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PnP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize point cloud\n",
    "display_point_cloud(\n",
    "    sparse_loc,\n",
    "    [cam1_loc, cam2_loc], \n",
    "    plot_scale=7,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('belpy_gdal')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5257680a82f661cea8699dc8fe4567e52d11c753044270df4ff2b694c33cdedf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
