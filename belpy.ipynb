{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input parameters are valid.\n",
      "\n",
      "Image datastores created successfully.\n",
      "Loaded previous matches\n"
     ]
    }
   ],
   "source": [
    "from lib.validate_inputs import validate\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pickle\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import pydegensac\n",
    "import open3d as o3d\n",
    "\n",
    "from pathlib import Path\n",
    "from easydict import EasyDict as edict\n",
    "\n",
    "from lib.classes import (Camera, Imageds, Features, Targets)\n",
    "from lib.config import parse_yaml_cfg\n",
    "from lib.sfm.two_view_geometry import Two_view_geometry, Single_camera_geometry\n",
    "from lib.sfm.triangulation import Triangulate\n",
    "from lib.match_pairs import match_pair\n",
    "from lib.track_matches import track_matches\n",
    "\n",
    "from lib.geometry import (project_points,\n",
    "                          compute_reprojection_error\n",
    "                          )\n",
    "from lib.utils import (build_dsm,\n",
    "                       generate_ortophoto,\n",
    "                       )\n",
    "from lib.point_clouds import (create_point_cloud,\n",
    "                              write_ply,\n",
    "                              )\n",
    "from lib.visualization import (display_point_cloud,\n",
    "                               display_pc_inliers,\n",
    "                               plot_features,\n",
    "                               plot_projections,\n",
    "                               )\n",
    "from lib.misc import (convert_to_homogeneous,\n",
    "                      convert_from_homogeneous,\n",
    "                      create_directory,\n",
    "                      )\n",
    "\n",
    "from thirdparty.transformations import affine_matrix_from_points\n",
    "\n",
    "# Parse options from yaml file\n",
    "cfg_file = 'config/config_base.yaml'\n",
    "cfg = parse_yaml_cfg(cfg_file)\n",
    "\n",
    "# Inizialize Variables\n",
    "cams = cfg.paths.cam_names\n",
    "features = dict.fromkeys(cams)  # @TODO: put this in an inizialization function\n",
    "\n",
    "# Create Image Datastore objects\n",
    "images = dict.fromkeys(cams)  # @TODO: put this in an inizialization function\n",
    "for cam in cams:\n",
    "    images[cam] = Imageds(cfg.paths.imdir / cam)\n",
    "\n",
    "cfg = validate(cfg, images)\n",
    "\n",
    "''' Perform matching and tracking '''\n",
    "# Load matching and tracking configurations\n",
    "with open(cfg.matching_cfg) as f:\n",
    "    opt_matching = edict(json.load(f))\n",
    "with open(cfg.tracking_cfg) as f:\n",
    "    opt_tracking = edict(json.load(f))\n",
    "\n",
    "# epoch = 0\n",
    "if cfg.proc.do_matching:\n",
    "    for cam in cams:\n",
    "        features[cam] = []\n",
    "\n",
    "    for epoch in cfg.proc.epoch_to_process:\n",
    "        print(f'Processing epoch {epoch}...')\n",
    "\n",
    "        # opt_matching = cfg.matching.copy()\n",
    "        epochdir = Path(cfg.paths.resdir) / f'epoch_{epoch}'\n",
    "\n",
    "        #-- Find Matches at current epoch --#\n",
    "        print(f'Run Superglue to find matches at epoch {epoch}')\n",
    "        opt_matching.output_dir = epochdir\n",
    "        pair = [\n",
    "            images[cams[0]].get_image_path(epoch),\n",
    "            images[cams[1]].get_image_path(epoch)\n",
    "        ]\n",
    "        # Call matching function\n",
    "        matchedPts, matchedDescriptors, matchedPtsScores = match_pair(\n",
    "            pair, cfg.images.bbox, opt_matching\n",
    "        )\n",
    "\n",
    "        # Store matches in features structure\n",
    "        for jj, cam in enumerate(cams):\n",
    "            # Dict keys are the cameras names, internal list contain epoches\n",
    "            features[cam].append(Features())\n",
    "            features[cam][epoch].append_features({\n",
    "                'kpts': matchedPts[jj],\n",
    "                'descr': matchedDescriptors[jj],\n",
    "                'score': matchedPtsScores[jj]\n",
    "            })\n",
    "            # @TODO: Store match confidence!\n",
    "\n",
    "        #=== Track previous matches at current epoch ===#\n",
    "        if cfg.proc.do_tracking and epoch > 0:\n",
    "            print(f'Track points from epoch {epoch-1} to epoch {epoch}')\n",
    "\n",
    "            trackoutdir = epochdir / f'from_t{epoch-1}'\n",
    "            opt_tracking['output_dir'] = trackoutdir\n",
    "            pairs = [\n",
    "                [images[cams[0]].get_image_path(epoch-1),\n",
    "                    images[cams[0]].get_image_path(epoch)],\n",
    "                [images[cams[1]].get_image_path(epoch-1),\n",
    "                    images[cams[1]].get_image_path(epoch)],\n",
    "            ]\n",
    "            prevs = [\n",
    "                features[cams[0]][epoch-1].get_features_as_dict(),\n",
    "                features[cams[1]][epoch-1].get_features_as_dict()\n",
    "            ]\n",
    "            # Call actual tracking function\n",
    "            tracked_cam0, tracked_cam1 = track_matches(\n",
    "                pairs, cfg.images.bbox, prevs, opt_tracking)\n",
    "            # @TODO: keep track of the epoch in which feature is matched\n",
    "            # @TODO: Check bounding box in tracking\n",
    "            # @TODO: clean tracking code\n",
    "\n",
    "            # Store all matches in features structure\n",
    "            features[cams[0]][epoch].append_features(tracked_cam0)\n",
    "            features[cams[1]][epoch].append_features(tracked_cam1)\n",
    "\n",
    "        # Run Pydegensac to estimate F matrix and reject outliers\n",
    "        F, inlMask = pydegensac.findFundamentalMatrix(\n",
    "            features[cams[0]][epoch].get_keypoints(),\n",
    "            features[cams[1]][epoch].get_keypoints(),\n",
    "            px_th=1.5, conf=0.99999, max_iters=10000,\n",
    "            laf_consistensy_coef=-1.0,\n",
    "            error_type='sampson',\n",
    "            symmetric_error_check=True,\n",
    "            enable_degeneracy_check=True,\n",
    "        )\n",
    "        print(f'Matching at epoch {epoch}: pydegensac found {inlMask.sum()} \\\n",
    "            inliers ({inlMask.sum()*100/len(features[cams[0]][epoch]):.2f}%)')\n",
    "        features[cams[0]][epoch].remove_outliers_features(inlMask)\n",
    "        features[cams[1]][epoch].remove_outliers_features(inlMask)\n",
    "\n",
    "        # Write matched points to disk\n",
    "        im_stems = images[cams[0]].get_image_stem(\n",
    "            epoch), images[cams[1]].get_image_stem(epoch)\n",
    "        for jj, cam in enumerate(cams):\n",
    "            features[cam][epoch].save_as_txt(\n",
    "                epochdir / f'{im_stems[jj]}_mktps.txt')\n",
    "        with open(epochdir / f'{im_stems[0]}_{im_stems[1]}_features.pickle', 'wb') as f:\n",
    "            pickle.dump(features, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        last_match_path = create_directory('res/last_epoch')\n",
    "        with open(last_match_path / 'last_features.pickle', 'wb') as f:\n",
    "            pickle.dump(features, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        print('Matching completed')\n",
    "\n",
    "elif not features[cams[0]]:\n",
    "    last_match_path = 'res/last_epoch/last_features.pickle'\n",
    "    with open(last_match_path, 'rb') as f:\n",
    "        features = pickle.load(f)\n",
    "        print(\"Loaded previous matches\")\n",
    "else:\n",
    "    print(\"Features already present, nothing was changed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstructing epoch 0...\n",
      "Using OPENCV camera model.\n",
      "Using OPENCV camera model.\n",
      "Space resection succeded. Number of inlier points: 12/14\n",
      "Relative Orientation - valid points: 3285/3769\n",
      "Point triangulation succeded: 1.0.\n",
      "Loaded image IMG_1289.jpg\n",
      "Points color interpolated\n",
      "Point cloud filtered by Statistical Oulier Removal\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "''' SfM '''\n",
    "\n",
    "# Initialize variables @TODO: build function for variable inizialization\n",
    "cameras = dict.fromkeys(cams)\n",
    "cameras[cams[0]], cameras[cams[1]] = [], []\n",
    "pcd = []\n",
    "tform = []\n",
    "# @TODO: store this information in exif inside an Image Class\n",
    "im_height, im_width = 4000, 6000\n",
    "\n",
    "\n",
    "# Read target image coordinates and object coordinates \n",
    "# @TODO: include onbject coordinate reading in methods\n",
    "targets = [Targets(cam_id=[0, 1],  im_coord_path=cfg.georef.target_paths),]\n",
    "targets[0].obj_coor = np.loadtxt(\"data/target_world.csv\",\n",
    "                              delimiter=\",\")\n",
    "\n",
    "# Camera baseline\n",
    "baseline_world = np.linalg.norm(\n",
    "    cfg.georef.camera_centers_world[0] - cfg.georef.camera_centers_world[1]\n",
    "    )\n",
    "\n",
    "for epoch in cfg.proc.epoch_to_process:\n",
    "    # epoch = 0\n",
    "    print(f'Reconstructing epoch {epoch}...')\n",
    "\n",
    "    # Initialize Intrinsics\n",
    "    ''' Inizialize Camera Intrinsics at every epoch setting them equal to\n",
    "        the reference cameras ones.\n",
    "    '''\n",
    "    # @TODO: replace append with insert or a more robust data structure...\n",
    "    for cam in cams:\n",
    "        cameras[cam].append(\n",
    "            Camera(\n",
    "                width=im_width,\n",
    "                height=im_height,\n",
    "                calib_path=cfg.paths.caldir / f'{cam}.txt'\n",
    "            )\n",
    "        )\n",
    "            \n",
    "    #--- Perform Space resection of the first camera by using GCPs ---#\n",
    "    ''' Initialize Single_camera_geometry class with a cameras object'''\n",
    "    # Temporary block to copy targets infos for every epoch\n",
    "    if len(targets) == 1:\n",
    "        targets.append(targets[0])\n",
    "    \n",
    "    space_resection = Single_camera_geometry(cameras[cams[0]][epoch])\n",
    "    space_resection.space_resection(\n",
    "        targets[epoch].get_im_coord(cam_id=0),\n",
    "        targets[epoch].get_obj_coord()\n",
    "        )\n",
    "    # Store result in camera 0 object\n",
    "    cameras[cams[0]][epoch] = space_resection.camera\n",
    "    \n",
    "    #--- Perform Relative orientation of the two cameras ---#\n",
    "    ''' Initialize Two_view_geometry class with a list containing the two cameras and a list contaning the matched features location on each camera.\n",
    "    '''\n",
    "    relative_ori = Two_view_geometry(\n",
    "        [cameras[cams[0]][epoch], cameras[cams[1]][epoch]],\n",
    "        [features[cams[0]][epoch].get_keypoints(),\n",
    "         features[cams[1]][epoch].get_keypoints()],\n",
    "    )\n",
    "    relative_ori.relative_orientation(\n",
    "        threshold=1.5, \n",
    "        confidence=0.999999, \n",
    "        scale_factor=261.60624502293524,\n",
    "        )\n",
    "    # Store result in camera 1 object\n",
    "    cameras[cams[1]][epoch] = relative_ori.cameras[1]\n",
    "    \n",
    "    # cam_baseline = np.linalg.norm(\n",
    "    #     cameras[cams[0]][0].get_C_from_pose() -\n",
    "    #     cameras[cams[1]][0].get_C_from_pose()\n",
    "    # )\n",
    "    # scale_fct = baseline_world / cam_baseline\n",
    "    # scale_fct = 261.60624502293524\n",
    "    \n",
    "    # Fix the EO of both the cameras as those estimated in the first epoch\n",
    "    # if epoch > 0:\n",
    "    #     for cam in cams:\n",
    "    #         cameras[cam][epoch] = cameras[cam][0]\n",
    "    #     print('Camera exterior orientation fixed to that of the master cameras.')\n",
    "\n",
    "    #--- Triangulate Points ---#\n",
    "    ''' Initialize Triangulate class with a list containing the two cameras\n",
    "        and a list contaning the matched features location on each camera.\n",
    "        Triangulated points are saved as points3d proprierty of the\n",
    "        Triangulate object (eg., triangulation.points3d)\n",
    "    '''\n",
    "    triangulation = Triangulate(\n",
    "        [cameras[cams[0]][epoch], \n",
    "         cameras[cams[1]][epoch]],\n",
    "        [features[cams[0]][epoch].get_keypoints(),\n",
    "         features[cams[1]][epoch].get_keypoints()]\n",
    "    )\n",
    "    triangulation.triangulate_two_views()\n",
    "    triangulation.interpolate_colors_from_image(\n",
    "        images[cams[1]][epoch],\n",
    "        cameras[cams[1]][epoch],\n",
    "        convert_BRG2RGB=True,\n",
    "    )\n",
    "\n",
    "  \n",
    "    # Create point cloud and save .ply to disk\n",
    "    pcd_epc = create_point_cloud(\n",
    "        triangulation.points3d, triangulation.colors)\n",
    "\n",
    "    # Filter outliers in point cloud with SOR filter\n",
    "    if cfg.other.do_SOR_filter:\n",
    "        _, ind = pcd_epc.remove_statistical_outlier(nb_neighbors=10,\n",
    "                                                    std_ratio=3.0)\n",
    "        #     display_pc_inliers(pcd_epc, ind)\n",
    "        pcd_epc = pcd_epc.select_by_index(ind)\n",
    "        print(\"Point cloud filtered by Statistical Oulier Removal\")\n",
    "\n",
    "    # Write point cloud to disk and store it in Point Cloud List\n",
    "    write_ply(pcd_epc, f'res/pt_clouds/sparse_pts_t{epoch}.ply')\n",
    "    pcd.append(pcd_epc)\n",
    "\n",
    "print('Done.')\n",
    "\n",
    "\n",
    "# Visualize point cloud\n",
    "display_point_cloud(\n",
    "    pcd,\n",
    "    [cameras[cams[0]][epoch], cameras[cams[1]][epoch]],\n",
    "    plot_scale=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# sparse_loc = o3d.io.read_point_cloud('data/belvedere_20220728_sparse_LOC.ply')\n",
    "# display_point_cloud(\n",
    "#     [pcd[0], sparse_loc],\n",
    "#     [cameras[cams[0]][epoch], cameras[cams[1]][epoch]],\n",
    "#     plot_scale=10,\n",
    "# )\n",
    "\n",
    "\n",
    "#  Coregistration\n",
    "# if cfg.proc.do_coregistration:\n",
    "#     # @TODO: make wrappers to handle RS transformations\n",
    "\n",
    "#     # Triangulate targets\n",
    "#     triangulate = Triangulate(\n",
    "#         [cameras[cams[0]][epoch], cameras[cams[1]][epoch]],\n",
    "#         [targets.get_im_coord(0)[epoch],\n",
    "#          targets.get_im_coord(1)[epoch]],\n",
    "#     )\n",
    "#     targets.append_obj_cord(triangulate.triangulate_two_views())\n",
    "\n",
    "#     # Estimate rigid body transformation between first epoch RS and current epoch RS\n",
    "#     # @TODO: make a wrapper for this\n",
    "#     v0 = np.concatenate((cameras[cams[0]][0].C,\n",
    "#                          cameras[cams[1]][0].C,\n",
    "#                          targets.get_obj_coord()[0].reshape(3, 1),\n",
    "#                          ), axis=1)\n",
    "#     v1 = np.concatenate((cameras[cams[0]][epoch].C,\n",
    "#                          cameras[cams[1]][epoch].C,\n",
    "#                          targets.get_obj_coord()[epoch].reshape(3, 1),\n",
    "#                          ), axis=1)\n",
    "#     tform.append(affine_matrix_from_points(\n",
    "#         v1, v0, shear=False, scale=False, usesvd=True))\n",
    "#     print('Point cloud coregistered based on {len(v0)} points.')\n",
    "# elif epoch > 0:\n",
    "#        # Fix the EO of both the cameras as those estimated in the first epoch\n",
    "#        for cam in cams:\n",
    "#             cameras[cam][epoch] = cameras[cam][0]\n",
    "#         print('Camera exterior orientation fixed to that of the master cameras.')\n",
    "\n",
    "# if cfg.proc.do_coregistration:\n",
    "#     # Apply rigid body transformation to triangulated points\n",
    "#     # @TODO: make wrapper for apply transformation to arrays\n",
    "#     pts = np.dot(tform[epoch],\n",
    "#                  convert_to_homogeneous(triangulation.points3d.T)\n",
    "#                  )\n",
    "#     triangulation.points3d = convert_from_homogeneous(pts).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded image IMG_2814.jpg\n",
      "Marker exported successfully\n",
      "Points exported successfully\n"
     ]
    }
   ],
   "source": [
    "'''Export image coordinates'''\n",
    "\n",
    "# from lib.io import export_keypoints_for_calge\n",
    "def export_keypoints_for_calge(\n",
    "    filename: str,\n",
    "    features: Features,\n",
    "    imageds: Imageds,\n",
    "    epoch: int = None,\n",
    "    pixel_size_micron: float = None,\n",
    ") -> None:\n",
    "    \"\"\" Write keypoints image coordinates to csv file,\n",
    "    sort by camera, as follows:\n",
    "    cam1, kpt1, x, y\n",
    "    cam1, kpt2, x, y\n",
    "    ...\n",
    "    cam1, kptM, x, y\n",
    "    cam2, kpt1, x, y\n",
    "    ....\n",
    "    camN, kptM, x, y\n",
    "\n",
    "    Args:\n",
    "        filename (str): path of the output csv file\n",
    "        features (calsses.Features):\n",
    "        imageds (calsses.Imageds):\n",
    "        epoch (int, default = None):\n",
    "        pixel_size_micron (float, default = None) [micron]\n",
    "    \"\"\"\n",
    "\n",
    "    if epoch is not None:\n",
    "\n",
    "        cams = list(imageds.keys())\n",
    "\n",
    "        # Write header to file\n",
    "        file = open(filename, \"w\")\n",
    "        if pixel_size_micron is not None:\n",
    "            file.write(\"image_name, feature_id, xi, eta\\n\")\n",
    "            img = imageds[cams[0]][epoch]\n",
    "            img_size = img.shape[:2]\n",
    "        else:\n",
    "            file.write(\"image_name, feature_id, x, y\\n\")\n",
    "\n",
    "        for cam in cams:\n",
    "            image_name = imageds[cam].get_image_name(epoch)\n",
    "            \n",
    "            # Write image name line \n",
    "            # NB: must be manually modified if it contains characters of symbols\n",
    "            file.write(f\"{image_name}\\n\")\n",
    "\n",
    "            for id, kpt in enumerate(features[cam][epoch].get_keypoints()):\n",
    "                x, y = kpt\n",
    "\n",
    "                # If pixel_size_micron is not empty, convert image coordinates from x-y (row,column) image coordinate system to xi-eta image coordinate system (origin at the center of the image, xi towards right, eta upwards)\n",
    "                if pixel_size_micron is not None:\n",
    "                    xi = (x - img_size[1]/2) * pixel_size_micron\n",
    "                    eta = (img_size[0]/2 - y) * pixel_size_micron\n",
    "\n",
    "                    file.write(\n",
    "                        f\"{id:05}{xi:10.1f}{eta:15.1f} \\n\")\n",
    "                else:\n",
    "                    file.write(\n",
    "                        f\"{id:05}{x:10.1f}{y:15.1f} \\n\")\n",
    "            # Write end image line\n",
    "            file.write(f\"-99\\n\")\n",
    "\n",
    "        file.close()\n",
    "        print(\"Marker exported successfully\")\n",
    "    else:\n",
    "        print('please, provide the epoch number.')\n",
    "        return\n",
    "\n",
    "''' Export object coordinates'''\n",
    "def export_points3D_for_calge(\n",
    "    filename: str,\n",
    "    points3D: np.ndarray,\n",
    ") -> None:\n",
    "    \"\"\" Write 3D world coordinates of matched points to csv file,\n",
    "    sort by camera, as follows:\n",
    "    marker1, X, Y, Z\n",
    "    ...\n",
    "    markerM, X, Y, Z\n",
    "\n",
    "    Args:\n",
    "        filename (str): path of the output csv file\n",
    "        points3D (np.ndarray):\n",
    "    \"\"\"\n",
    "\n",
    "    # Write header to file\n",
    "    file = open(filename, \"w\")\n",
    "    file.write(\"point_id, X, Y, Z\\n\")\n",
    "    \n",
    "    for id, pt in enumerate(points3D):\n",
    "        file.write(f\"{id:05}{pt[0]:20.4f}{pt[1]:25.4f}{pt[2]:24.4f}\\n\")\n",
    "\n",
    "    file.close()\n",
    "    print(\"Points exported successfully\")\n",
    "\n",
    "\n",
    "epoch = 0\n",
    "export_keypoints_for_calge('simulaCalge/keypoints_280722.txt',\n",
    "                           features=features,\n",
    "                           imageds=images,\n",
    "                           epoch=epoch,\n",
    "                           pixel_size_micron=3.773\n",
    "                           )\n",
    "export_points3D_for_calge('simulaCalge/points3D_280722.txt',\n",
    "                           points3D=np.asarray(pcd[epoch].points)\n",
    "                           )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import open3d as o3d\n",
    "\n",
    "# # from traceback import print_tb\n",
    "\n",
    "# from lib.visualization import display_point_cloud\n",
    "# from thirdparty.transformations import euler_from_matrix, euler_matrix\n",
    "\n",
    "# cam1_loc = ref_cams[cams[0]]\n",
    "# cam2_loc = ref_cams[cams[1]]\n",
    "\n",
    "# # IMG_1289.jpg\n",
    "# # loc = np.array([312.930747,300.536595,135.159918]).reshape(3,-1)\n",
    "# # angles = np.deg2rad(np.array([-83.914310,80.177810,174.222339]))\n",
    "\n",
    "# # IMG_2814.jpg\n",
    "# loc = np.array([151.703845, 99.171778, 91.618363]).reshape(3, -1)\n",
    "# ang = np.deg2rad(np.array([100.281584, 54.781799, -12.652574]))\n",
    "# R1_world2cam = euler_matrix(ang[0], ang[1], ang[2])[:3, :3]\n",
    "# # print(R_world2cam1_loc)\n",
    "\n",
    "# # Read point cloud in LOC RS\n",
    "# sparse_loc = o3d.io.read_point_cloud('data/belvedere_20220728_sparse_LOC.ply')\n",
    "\n",
    "# # Define cam1_locera EO\n",
    "\n",
    "\n",
    "# def build_pose_matrix(R: np.ndarray, C: np.ndarray) -> np.ndarray:\n",
    "#     # Check for input dimensions\n",
    "#     if R.shape != (3, 3):\n",
    "#         raise ValueError(\n",
    "#             'Wrong dimension of the R matrix. It must be a 3x3 numpy array')\n",
    "#     if C.shape == (3,) or C.shape == (1, 3):\n",
    "#         C = C.T\n",
    "#     elif C.shape != (3, 1):\n",
    "#         raise ValueError(\n",
    "#             'Wrong dimension of the C vector. It must be a 3x1 or a 1x3 numpy array')\n",
    "\n",
    "#     pose = np.eye(4)\n",
    "#     pose[0:3, 0:3] = R\n",
    "#     pose[0:3, 3:4] = C\n",
    "#     return pose\n",
    "\n",
    "\n",
    "# def compute_camera_EO(camera: Camera,\n",
    "#                       extrinsics: np.ndarray = None,\n",
    "#                       pose: np.ndarray = None\n",
    "#                       ) -> Camera:\n",
    "\n",
    "#     if extrinsics is not None:\n",
    "#         camera.extrinsics = extrinsics\n",
    "#         camera.extrinsics_to_pose()\n",
    "#         camera.update_camera_from_extrinsics()\n",
    "#         return camera\n",
    "\n",
    "#     if pose is not None:\n",
    "#         camera.pose = pose\n",
    "#         camera.pose_to_extrinsics()\n",
    "#         camera.update_camera_from_extrinsics()\n",
    "#         return camera\n",
    "\n",
    "#     else:\n",
    "#         raise ValueError(\n",
    "#             'Not enough data to build Camera External Orientation matrixes.')\n",
    "\n",
    "\n",
    "# cam1toWorld = build_pose_matrix(R1_world2cam.T, loc) @ cameras[cams[0]][0].pose\n",
    "# cam1_loc = compute_camera_EO(cam1_loc, pose=cam1toWorld)\n",
    "\n",
    "# cam2toWorld = cam1_loc.pose @ cameras[cams[1]][0].pose\n",
    "# cam2_loc = compute_camera_EO(cam2_loc, pose=cam2toWorld)\n",
    "\n",
    "\n",
    "# # Visualize point cloud\n",
    "# display_point_cloud(\n",
    "#     sparse_loc,\n",
    "#     [cam1_loc, cam2_loc],\n",
    "#     plot_scale=7,\n",
    "# )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('belpy_gdal')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5257680a82f661cea8699dc8fe4567e52d11c753044270df4ff2b694c33cdedf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
