#- Define paths and base settings
# paths:
image_dir: "data/img2022"
calibration_dir: "data/calib"
results_dir: "res"
camera_names: ["p1", "p2"] # ['p0_00', 'p1_00'] #
matching_cfg: "config/opt_matching.json"
tracking_cfg: "config/opt_tracking.json"

#- Processing options
# processing:
#- Epoches to process
# It can be either 'all' for processing all the epochs
# or a list with the epoches to be processed
epoch_to_process: [0] #"all" # [0, 1]  #  [x for x in range(15)]

#- Switches to find and track matches
do_matching: True
do_tracking: True

#- Coregistration switches
# If True, try to coregister point clouds based on n double points
# @TODO: still have to fully implement it and move code to a specific Class
do_coregistration: False

#- Fix Cameras:
# if False, estimate EO of cam2 with relative orientation, otherwise keep both cameras fixed.
# fix_both_cameras: False

#- Image-related options
# images:
#- Bounding box for processing the images from the two cameras
# It must be a list of list (one instance for each camera) 
# with the min/max coordinates
# in the format of:
# [xmin, ymin, xmax, ymax] 
# 
mask_bounding_box: [
  [1000, 1500, 5600, 3700], 
  [100, 1800, 4700, 4000],
]

#- Georeferencing (i.e., absolute orientation) information
# georef:
#- Camera centers obtained from Metashape model in July [m]
camera_centers_world: [
  [312.930, 300.536, 135.159], # IMG_2092
  [151.703, 99.171, 91.618], # IMG_0481
]


#- Targets' information
target_paths: ["data/target_image_p1.txt", "data/target_image_p2.txt"]

#- Other On-Off switches
# others:
#- visualize outputs
do_viz: False

#- Point cloud processing
do_SOR_filter: True

# Matching options
detector: "Superpoint"
matcher: "Superglue"
output_dir: "./res"
device: 'gpu'
resize: [-1]
keypoint_threshold: 0.0001
max_keypoints: 10240  
superglue_model: "outdoor"
match_threshold: 0.15
do_viz: True
show_keypoints: False

# Tile processing
# useTile: True
# writeTile2Disk: False
# do_viz_tile: True
# rowDivisor: 2
# colDivisor: 4
# overlap: 400
