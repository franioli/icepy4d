{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4dcf045-a1cb-4844-88de-bd657e430c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Belvedere stereo matching\n",
    "# \n",
    "# \n",
    "# \n",
    "# v0.1 2022.05.17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c2bdc86-eeda-46f8-8cc2-800da7eaf51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import cv2 \n",
    "import  pydegensac\n",
    "import pickle\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib widget\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "from utils.utils import read_img\n",
    "from utils.match_pairs import match_pair\n",
    "from utils.track_matches import track_matches\n",
    "from utils.sg.utils import make_matching_plot\n",
    "\n",
    "#  Parameters (to be put in parser)\n",
    "\n",
    "rootDirPath = '.'\n",
    "\n",
    "#- Folders and paths\n",
    "imFld = 'data/img'\n",
    "imExt = '.tif'\n",
    "calibFld = 'data/calib'\n",
    "\n",
    "#- CAMERAS\n",
    "numCams = 2\n",
    "camNames = ['p2', 'p3']\n",
    "\n",
    "#- Image cropping boundaries\n",
    "maskBB = [[600,1900,5300, 3600], [800,1800,5500,3500]]             # Bounding box for processing the images from the two cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ef4a0b6-47dc-451b-83a8-d35df36905f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data:...\n"
     ]
    }
   ],
   "source": [
    "#  Load data\n",
    "print('Loading data:...')\n",
    "\n",
    "cameras = []                                                            # List for storing cameras information (as dicts)\n",
    "images = []                                                            # List for storing image paths\n",
    "features = []                                                            # Dict for storing all the valid matched features at all epochs\n",
    "\n",
    "#- images\n",
    "for jj, cam in enumerate(camNames):\n",
    "    d  = os.listdir(os.path.join(rootDirPath, imFld, cam))\n",
    "    for i, f in enumerate(d):\n",
    "        d[i] = os.path.join(rootDirPath, imFld, cam, f)\n",
    "    d.sort()\n",
    "    if jj > 0 and len(d) is not len(images[jj-1]):\n",
    "        print('Error: different number of images per camera')\n",
    "    else:\n",
    "        images.insert(jj, d)\n",
    "\n",
    "#- Cameras structures\n",
    "# TO DO: implement camera class!\n",
    "for jj, cam in enumerate(camNames):\n",
    "    path = (os.path.join(rootDirPath, calibFld, cam+'.txt'))\n",
    "    with open(path, 'r') as f:\n",
    "        data = np.loadtxt(f)\n",
    "    K = data[0:9].astype(float).reshape(3, 3, order='C')\n",
    "    dist = data[9:13].astype(float)\n",
    "    cameras.insert(jj, {'K': K, 'dist': dist})\n",
    "\n",
    "# Remove some variables\n",
    "del d, data, K, dist, path, f, i, jj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a90f37-afdc-4030-8888-a64809ccc6cf",
   "metadata": {},
   "source": [
    "# Process epoches "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba9049e7-3ee0-41b4-8f9d-a79f43004030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing epoch 0...\n",
      "Run Superglue to find matches at epoch 0\n",
      "Will not resize images\n",
      "Running inference on device \"cuda\"\n",
      "Loaded SuperPoint model\n",
      "Loaded SuperGlue model (\"outdoor\" weights)\n",
      "Will write matches to directory \"res/epoch_0\"\n",
      "Will write visualization images to directory \"res/epoch_0\"\n",
      "Warning: input resolution is very large, results may vary\n",
      "Warning: input resolution is very large, results may vary\n",
      "Images subdivided in 2x3 tiles\n",
      "[Finished Tile Pairs  0 -  0 of  6] matcher=9.048 total=9.048 sec {0.1 FPS} \n",
      "[Finished Tile Pairs  1 -  1 of  6] matcher=8.897 total=8.897 sec {0.1 FPS} \n",
      "[Finished Tile Pairs  2 -  2 of  6] matcher=9.396 total=9.396 sec {0.1 FPS} \n",
      "[Finished Tile Pairs  3 -  3 of  6] matcher=9.848 total=9.848 sec {0.1 FPS} \n",
      "[Finished Tile Pairs  4 -  4 of  6] matcher=10.084 total=10.084 sec {0.1 FPS} \n",
      "[Finished Tile Pairs  5 -  5 of  6] matcher=10.296 total=10.296 sec {0.1 FPS} \n",
      "pydegensac found 2678 inliers (65.70%)\n",
      "[Finished pair] load_image=0.903 create_tiles=0.028 PyDegensac=62.177 viz_match=3.696 total=66.804 sec {0.0 FPS} \n"
     ]
    }
   ],
   "source": [
    "epoches2process = [0] # #1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n",
    "\n",
    "\n",
    "for epoch in epoches2process:\n",
    "    print(f'Processing epoch {epoch}...')\n",
    "\n",
    "    #=== Find Matches at current epoch ===#\n",
    "    print('Run Superglue to find matches at epoch {}'.format(epoch))    \n",
    "    epochdir = os.path.join('res','epoch_'+str(epoch))      \n",
    "    pair = [images[0][epoch], images[1][epoch]]\n",
    "    maskBB = np.array(maskBB).astype('int')\n",
    "    opt_matching ={'output_dir': epochdir, \n",
    "                   \n",
    "                   'resize': [-1],\n",
    "                   'resize_float': True,\n",
    "                   'equalize_hist': False,\n",
    "    \n",
    "                   'nms_radius': 4 , \n",
    "                   'keypoint_threshold': 0.0001, \n",
    "                   'max_keypoints': 4096, \n",
    "                   \n",
    "                   'superglue': 'outdoor',\n",
    "                   'sinkhorn_iterations': 100,\n",
    "                   'match_threshold': 0.2, \n",
    "                 \n",
    "                   'viz':  True,\n",
    "                   'viz_extension': 'png', \n",
    "                   'fast_viz': True,\n",
    "                   'opencv_display' : False, \n",
    "                   'show_keypoints': False, \n",
    "                                      \n",
    "                   'cache': False,\n",
    "                   'force_cpu': False,\n",
    "                             \n",
    "                   'useTile': True, \n",
    "                   'writeTile2Disk': False,\n",
    "                   'do_viz_tile': False,\n",
    "                   'rowDivisor': 2,\n",
    "                   'colDivisor': 3,\n",
    "                   'overlap': 300,            \n",
    "                   }\n",
    "    matchedPts, matchedDescriptors, matchedPtsScores, _ = match_pair(pair, maskBB, opt_matching)\n",
    "        \n",
    "    # Store matches in features structure\n",
    "    if epoch == 0:\n",
    "        features = [{   'mkpts0': matchedPts['mkpts0'], \n",
    "                        'mkpts1': matchedPts['mkpts1'],\n",
    "                        # 'mconf': matchedPts['match_confidence'],\n",
    "                        'descr0': matchedDescriptors[0], \n",
    "                        'descr1': matchedDescriptors[1],\n",
    "                        'scores0': matchedPtsScores[0], \n",
    "                        'scores1': matchedPtsScores[1] }] \n",
    "    \n",
    "    \n",
    "    #=== Track previous matches at current epoch ===#\n",
    "    if epoch > 0:\n",
    "        print('Track points from epoch {} to epoch {}'.format(epoch-1, epoch))\n",
    "        \n",
    "        trackoutdir = os.path.join('res','epoch_'+str(epoch), 'from_t'+str(epoch-1))\n",
    "        pairs = [ [ images[0][epoch-1], images[0][epoch] ], \n",
    "                  [ images[1][epoch-1], images[1][epoch] ] ] \n",
    "        maskBB = np.array(maskBB).astype('int')\n",
    "        opt_tracking = {'output_dir': trackoutdir,\n",
    "                        \n",
    "                        'resize': [-1],\n",
    "                        'resize_float': True,\n",
    "                        'equalize_hist': False,\n",
    "         \n",
    "                        'nms_radius': 4 , \n",
    "                        'keypoint_threshold': 0.0001, \n",
    "                        'max_keypoints': 8192, \n",
    "                        \n",
    "                        'superglue': 'outdoor',\n",
    "                        'sinkhorn_iterations': 100,\n",
    "                        'match_threshold': 0.2, \n",
    "                      \n",
    "                        'viz':  True,\n",
    "                        'viz_extension': 'png',  \n",
    "                        'fast_viz': True,\n",
    "                        'opencv_display' : False, \n",
    "                        'show_keypoints': False, \n",
    "                        \n",
    "                        'cache': False,\n",
    "                        'force_cpu': False,\n",
    "                                  \n",
    "                        'useTile': True, \n",
    "                        'writeTile2Disk': False,\n",
    "                        'do_viz_tile': False,\n",
    "                        'rowDivisor': 2,\n",
    "                        'colDivisor': 4,\n",
    "                           }   \n",
    "        \n",
    "        prevs = [{'keypoints0': np.float32(features[epoch-1]['mkpts0']), \n",
    "                  'descriptors0': np.float32(features[epoch-1]['descr0']),\n",
    "                  'scores0': np.float32(features[epoch-1]['scores0']) }, \n",
    "                 {'keypoints0': np.float32(features[epoch-1]['mkpts1']), \n",
    "                  'descriptors0': np.float32(features[epoch-1]['descr1']), \n",
    "                  'scores0': np.float32(features[epoch-1]['scores1'])  }  ]\n",
    "        tracked_cam0, tracked_cam1 = track_matches(pairs, maskBB, prevs, opt_tracking)\n",
    "        # TO DO: tenere traccia anche dei descriptors and scores dei punti traccati!\n",
    "              \n",
    "        # Store all matches in features structure\n",
    "        features.append({'mkpts0': np.concatenate((matchedPts['mkpts0'], tracked_cam0['keypoints1']), axis=0 ), \n",
    "                         'mkpts1': np.concatenate((matchedPts['mkpts1'], tracked_cam1['keypoints1']), axis=0 ),\n",
    "                         # 'mconf': matchedPts['match_confidence'],\n",
    "                          'descr0': np.concatenate((matchedDescriptors[0], tracked_cam0['descriptors1']), axis=1 ),\n",
    "                          'descr1': np.concatenate((matchedDescriptors[1], tracked_cam1['descriptors1']), axis=1 ),\n",
    "                          'scores0': np.concatenate((matchedPtsScores[0], tracked_cam0['scores1']), axis=0 ), \n",
    "                          'scores1': np.concatenate((matchedPtsScores[1], tracked_cam1['scores1']), axis=0 ), \n",
    "                         })\n",
    "        \n",
    "        # Run Pydegensac to estimate F matrix and reject outliers                         \n",
    "        F, inlMask = pydegensac.findFundamentalMatrix(features[epoch]['mkpts0'], features[epoch]['mkpts1'], px_th=3, conf=0.9,\n",
    "                                                      max_iters=100000, laf_consistensy_coef=-1.0, error_type='sampson',\n",
    "                                                      symmetric_error_check=True, enable_degeneracy_check=True)\n",
    "        print('Matches at epoch {}: pydegensac found {} inliers ({:.2f}%)'.format(epoch, int(deepcopy(inlMask).astype(np.float32).sum()),\n",
    "                        int(deepcopy(inlMask).astype(np.float32).sum())*100 / len(features[epoch]['mkpts0'])))\n",
    "       \n",
    "    # Write matched points to disk   \n",
    "    stem0, stem1 = Path(images[0][epoch]).stem, Path(images[1][epoch]).stem\n",
    "    np.savetxt(os.path.join(epochdir, stem0+'_matchedPts.txt'), \n",
    "               features[epoch]['mkpts0'] , fmt='%i', delimiter=',', newline='\\n',\n",
    "               header='x,y') \n",
    "    np.savetxt(os.path.join(epochdir, stem1+'_matchedPts.txt'), \n",
    "               features[epoch]['mkpts1'] , fmt='%i', delimiter=' ', newline='\\n',                   \n",
    "               header='x,y') \n",
    "    with open(os.path.join(epochdir, stem0+'_'+stem1+'_features.pickle'), 'wb') as f:\n",
    "        pickle.dump(features, f, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef699362-7a6a-48e0-bfda-fefb95594c7e",
   "metadata": {},
   "source": [
    "# SfM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "aeb2e3ea-cb0e-4ca2-bb83-511e7d6786fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTS\n",
    "\n",
    "\n",
    "# image = cv2.imread(images[0][0], flags=cv2.IMREAD_COLOR)\n",
    "# h, w, _ = image.shape\n",
    "# h_new, w_new = h*downsample, w*downsample\n",
    "# # int(h_new)\n",
    "# K, dist = cameras[1]['K'],  cameras[1]['dist']\n",
    "# K_scaled, roi = cv2.getOptimalNewCameraMatrix(K, dist, (w, h), 1, (int(w_new), int(h_new)))\n",
    "\n",
    "# print(cameras[0]['K'])\n",
    "# print(K0_scaled)\n",
    "# print(cameras[1]['K'])\n",
    "# print(K1_scaled)\n",
    "# print(cameras[0]['dist'])\n",
    "# print(cameras[1]['dist'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "961523f3-ed81-4fa6-8d74-e1752a207536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pydegensac: 2678 inliers (100.00%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# undistort images\n",
    "def undistort_image(image, K, dist, downsample, out_name):\n",
    "    h, w, _ = image.shape\n",
    "    h_new, w_new = h*downsample, w*downsample\n",
    "    K_scaled, roi = cv2.getOptimalNewCameraMatrix(K, dist, (w, h), 1, (int(w_new), int(h_new)))\n",
    "    und = cv2.undistort(image, K, dist, None, K_scaled)\n",
    "    x, y, w, h = roi\n",
    "    und = und[y:y+h, x:x+w]                      \n",
    "    cv2.imwrite(out_name, und)\n",
    "    return und, K_scaled\n",
    "\n",
    "sgm_path = Path('./sgm')\n",
    "downsample = 0.25\n",
    "stem0 = Path(images[0][0]).stem\n",
    "stem1 = Path(images[1][0]).stem\n",
    "img0 = cv2.imread(images[0][0], flags=cv2.IMREAD_COLOR)\n",
    "img1 = cv2.imread(images[1][0], flags=cv2.IMREAD_COLOR)\n",
    "    \n",
    "name0 = str(sgm_path / 'und' / (stem0 + \"_undistorted.jpg\"))\n",
    "name1 = str(sgm_path / 'und' / (stem1 + \"_undistorted.jpg\"))\n",
    "img0, K0_scaled = undistort_image(img0, cameras[0]['K'],  cameras[0]['dist'], downsample, name0)\n",
    "img1, K1_scaled = undistort_image(img1, cameras[1]['K'],  cameras[1]['dist'], downsample, name1)\n",
    "\n",
    "# Rectify uncalibrated\n",
    "pts0, pts1 = features[0]['mkpts1']*downsample, features[0]['mkpts0']*downsample\n",
    "h, w, _ = img0.shape\n",
    "F, inlMask = pydegensac.findFundamentalMatrix(pts0, pts1, px_th=1, conf=0.99999,\n",
    "                                              max_iters=100000, laf_consistensy_coef=-1.0, error_type='sampson',\n",
    "                                              symmetric_error_check=True, enable_degeneracy_check=True)\n",
    "print('Pydegensac: {} inliers ({:.2f}%)'.format(inlMask.sum(), inlMask.sum()*100 / len(pts0)))\n",
    "success, H1, H0 = cv2.stereoRectifyUncalibrated(pts0, pts1 , F, (w,h))\n",
    "img0_rectified = cv2.warpPerspective(img0, H0, (w,h))\n",
    "img1_rectified = cv2.warpPerspective(img1, H1, (w,h))\n",
    "\n",
    "# fig = plt.figure()\n",
    "# ax1 = fig.add_subplot(1,2,1)\n",
    "# plt.imshow(cv2.cvtColor(img0_rectified, cv2.COLOR_BGR2RGB))\n",
    "# ax2 = fig.add_subplot(1,2,2)\n",
    "# plt.imshow(cv2.cvtColor(img1_rectified, cv2.COLOR_BGR2RGB))\n",
    "# plt.show()\n",
    "\n",
    "# cv2.imshow('i0 rect', img0_rectified)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "# cv2.imshow('i1 rect', img1_rectified)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "\n",
    "cv2.imwrite(str(sgm_path / (stem0 + \"_rectified.jpg\")), img0_rectified)\n",
    "cv2.imwrite(str(sgm_path / (stem1 + \"_rectified.jpg\")), img1_rectified)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1f6365c2-ef3a-49dc-ab18-a8644e5ca76d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid points: 2678/2678\n",
      "[[ 0.59806776  0.0867163  -0.79674039]\n",
      " [ 0.06992954  0.98469133  0.1596648 ]\n",
      " [ 0.79838889 -0.15120606  0.5828481 ]]\n",
      "[ 0.97158799 -0.2236987   0.07730251]\n"
     ]
    }
   ],
   "source": [
    "def estimate_pose(kpts0, kpts1, K0, K1, thresh, conf=0.99999):\n",
    "    if len(kpts0) < 5:\n",
    "        return None\n",
    "\n",
    "    f_mean = np.mean([K0[0, 0], K1[1, 1], K0[0, 0], K1[1, 1]])\n",
    "    norm_thresh = thresh / f_mean\n",
    "\n",
    "    kpts0 = (kpts0 - K0[[0, 1], [2, 2]][None]) / K0[[0, 1], [0, 1]][None]\n",
    "    kpts1 = (kpts1 - K1[[0, 1], [2, 2]][None]) / K1[[0, 1], [0, 1]][None]\n",
    "\n",
    "    E, mask = cv2.findEssentialMat(\n",
    "        kpts0, kpts1, np.eye(3), threshold=norm_thresh, prob=conf,\n",
    "        method=cv2.RANSAC)\n",
    "\n",
    "    assert E is not None\n",
    "\n",
    "    best_num_inliers = 0\n",
    "    ret = None\n",
    "    for _E in np.split(E, len(E) / 3):\n",
    "        n, R, t, _ = cv2.recoverPose(\n",
    "            _E, kpts0, kpts1, np.eye(3), 1e9, mask=mask)\n",
    "        if n > best_num_inliers:\n",
    "            best_num_inliers = n\n",
    "            ret = (R, t[:, 0], mask.ravel() > 0)\n",
    "    return ret\n",
    "\n",
    "def scale_intrinsics(K, scales):\n",
    "    scales = np.diag([1./scales[0], 1./scales[1], 1.])\n",
    "    return np.dot(scales, K)\n",
    "\n",
    "\n",
    "pts0, pts1 = features[0]['mkpts0']*downsample, features[0]['mkpts1']*downsample\n",
    "rel_pose = estimate_pose(pts0, pts1, K0_scaled, K1_scaled, thresh=2, conf=0.99999)\n",
    "R = rel_pose[0]\n",
    "t = rel_pose[1]\n",
    "valid = rel_pose[2]\n",
    "print('valid points: {}/{}'.format(valid.sum(),len(valid)))\n",
    "# print(R)\n",
    "# print(t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e79f42-3ea1-4d29-b112-e5caf7db97e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(images[0][0])\n",
    "# print(images[1][0])\n",
    "# features[0]['mkpts0']/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "db0758a4-d878-4a6b-80b8-0658d5a8b5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff540ae3-91ca-4a42-8fce-2c4f8527c2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # SGM OPENCV\n",
    "# blockSize = 5\n",
    "# min_disp = 128\n",
    "# max_disp = 512\n",
    "# num_disp = max_disp-min_disp\n",
    "# stereo = cv2.StereoSGBM_create(minDisparity = min_disp,\n",
    "#     numDisparities = num_disp,\n",
    "#     blockSize = blockSize,\n",
    "#     P1 = 8*1*blockSize**2,\n",
    "#     P2 = 32*1*blockSize**2,\n",
    "#     disp12MaxDiff = 0,\n",
    "#     uniquenessRatio = 5,\n",
    "#     speckleWindowSize = 100,\n",
    "#     speckleRange = 2,\n",
    "# )\n",
    "\n",
    "# imgR = img0_rectified\n",
    "# imgL = img1_rectified\n",
    "# print('computing disparity...')\n",
    "# disparity_SGBM = stereo.compute(imgL, imgR)\n",
    "# disparity_SGBM = cv2.normalize(disparity_SGBM, disparity_SGBM, alpha=255,\n",
    "#                               beta=0, norm_type=cv2.NORM_MINMAX)\n",
    "# # disparity_SGBM = cv2.validateDisparity(disparity_SGBM, cost, minDisparity, numberOfDisparities\n",
    "# cv2.imwrite(str(sgm_path / \"disparity_SGBM_norm.png\"), disparity_SGBM)\n",
    "# print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ae5a52-5eeb-428b-8c3a-1ce2135f025d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a9e916-0100-4c9c-8214-de015b032f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.imshow(\"Disparity\", cv2.resize(disparity_SGBM, (1920,1080)))\n",
    "# cv2.waitKey()\n",
    "# cv2.destroyAllWindows()\n",
    "\n",
    "# print('generating 3d point cloud...',)\n",
    "# h, w = imgL.shape[:2]\n",
    "# points = cv2.reprojectImageTo3D(disp, K)\n",
    "# colors = cv.cvtColor(imgL, cv.COLOR_BGR2RGB)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943a8466-9448-4aaf-b52d-f8ad1cecf7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ply_header = '''ply\n",
    "# format ascii 1.0\n",
    "# element vertex %(vert_num)d\n",
    "# property float x\n",
    "# property float y\n",
    "# property float z\n",
    "# property uchar red\n",
    "# property uchar green\n",
    "# property uchar blue\n",
    "# end_header\n",
    "# '''\n",
    "\n",
    "# def write_ply(fn, verts, colors):\n",
    "#     verts = verts.reshape(-1, 3)\n",
    "#     colors = colors.reshape(-1, 3)\n",
    "#     verts = np.hstack([verts, colors])\n",
    "#     with open(fn, 'wb') as f:\n",
    "#         f.write((ply_header % dict(vert_num=len(verts))).encode('utf-8'))\n",
    "#         np.savetxt(f, verts, fmt='%f %f %f %d %d %d ')\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
